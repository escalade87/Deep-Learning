{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Deep Learning Mid Term Exam #7 - Xavier and Adam.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "D468vNjsO308",
        "colab_type": "code",
        "outputId": "0688559e-e437-4d75-c5e9-2f20de583745",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "import numpy as np\n",
        "from tensorflow import keras\n",
        "import tensorflow as tf\n",
        "import matplotlib.pyplot as plt\n",
        "import scipy.io as sio\n",
        "from keras.utils import np_utils\n",
        "from keras.models import Model\n",
        "from keras.layers import Input, Dense, Flatten\n",
        "import keras.optimizers\n",
        "from keras import regularizers\n",
        "\n",
        "import time  # To time each epoch"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lK_qEiqNO633",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def load_data(DATA_NAME = 'notMNIST_small.mat'):\n",
        "\n",
        "    rows, cols = 28, 28\n",
        "    nb_classes = 10\n",
        "        \n",
        "    mat = sio.loadmat(DATA_NAME)\n",
        "\n",
        "    X = mat['images']\n",
        "    Y = mat['labels']\n",
        "\n",
        "    # Move last column to front\n",
        "    X = np.rollaxis(X, 2)\n",
        "\n",
        "    # Reshape and format input\n",
        "    X = X.reshape(X.shape[0], rows, cols, 1)\n",
        "    X = X.astype('float32')\n",
        "    X -= np.mean(X,axis=0)\n",
        "    X /= 255.0\n",
        "\n",
        "    # Hot encoding\n",
        "    Y = Y.astype(int)\n",
        "    Y = np_utils.to_categorical(Y, nb_classes)\n",
        "\n",
        "    # Divide into test and train sets\n",
        "    perm = np.random.permutation(X.shape[0])\n",
        "\n",
        "    train_size = 13000\n",
        "\n",
        "    X_train = X[perm[:train_size]]\n",
        "    X_test = X[perm[train_size:]]\n",
        "\n",
        "    Y_train = Y[perm[:train_size]]\n",
        "    Y_test = Y[perm[train_size:]]\n",
        "\n",
        "    return (X_train, Y_train, X_test, Y_test)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wGyyIfJNukkY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_images, train_labels , test_images, test_labels  = load_data()\n",
        "\n",
        "batch_size = 128\n",
        "nb_epoch = 20"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VP_KUWk1BjSm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.backend import sigmoid\n",
        "def swish(x, beta = 1):\n",
        "    return (x * sigmoid(beta * x))\n",
        "from keras.utils.generic_utils import get_custom_objects\n",
        "from keras.layers import Activation\n",
        "get_custom_objects().update({'swish': Activation(swish)})"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tWA-I955wigw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_model(activation='relu', initializer='glorot_uniform', hidden_size=128,regularizers=None):\n",
        "\n",
        "    # Model parameters\n",
        "    rows, cols = 28, 28\n",
        "    input_shape = (rows, cols, 1)\n",
        "\n",
        "    nb_classes = 10\n",
        "    \n",
        "    inp = Input(shape=input_shape)\n",
        "    flat = Flatten()(inp)\n",
        "    hidden_1 = Dense(hidden_size, activation=activation, kernel_initializer=initializer, \n",
        "                kernel_regularizer=regularizers)(flat)\n",
        "    out = Dense(nb_classes, activation='softmax')(hidden_1)\n",
        "\n",
        "    model = Model(inputs=inp, outputs=out)\n",
        "\n",
        "    print(model.summary())\n",
        "\n",
        "    return model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xPOcn8ZRtDeR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_model2(activation='relu', initializer='glorot_uniform', hidden_size=128,regularizers=None):\n",
        "\n",
        "    # Model parameters\n",
        "    rows, cols = 28, 28\n",
        "    input_shape = (rows, cols, 1)\n",
        "\n",
        "    nb_classes = 10\n",
        "    \n",
        "    inp = Input(shape=input_shape)\n",
        "    flat = Flatten()(inp)\n",
        "    hidden_1 = Dense(hidden_size, activation=activation, kernel_initializer=initializer,\n",
        "                kernel_regularizer=regularizers)(flat)\n",
        "    hidden_2 = Dense(hidden_size, activation=activation, kernel_initializer=initializer,\n",
        "                kernel_regularizer=regularizers)(hidden_1)\n",
        "    out = Dense(nb_classes, activation='softmax')(hidden_2)\n",
        "\n",
        "    model = Model(inputs=inp, outputs=out)\n",
        "\n",
        "    print(model.summary())\n",
        "\n",
        "    return model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q_VJDC2Ste7J",
        "colab_type": "text"
      },
      "source": [
        "With Xavier Initialization, One hidden layer with 32 input node, ReLU, Adam, without regularizer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fMrMvX5KWy01",
        "colab_type": "code",
        "outputId": "6bdd6a1c-47db-4d77-a0a3-f7330ca98ded",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "model = get_model(hidden_size=32)\n",
        "\n",
        "model.compile(loss='categorical_crossentropy', optimizer='adam',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "model.fit(train_images, train_labels, batch_size=batch_size, epochs=nb_epoch,\n",
        "          verbose=1, validation_data=(test_images, test_labels))\n",
        "\n",
        "score = model.evaluate(test_images, test_labels, verbose=1)\n",
        "\n",
        "print(\"Accuracy:\", score[1])\t  "
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model_1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_1 (InputLayer)         (None, 28, 28, 1)         0         \n",
            "_________________________________________________________________\n",
            "flatten_1 (Flatten)          (None, 784)               0         \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 32)                25120     \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 10)                330       \n",
            "=================================================================\n",
            "Total params: 25,450\n",
            "Trainable params: 25,450\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n",
            "Train on 13000 samples, validate on 5724 samples\n",
            "Epoch 1/20\n",
            "13000/13000 [==============================] - 0s 31us/step - loss: 0.8153 - accuracy: 0.7714 - val_loss: 0.4758 - val_accuracy: 0.8676\n",
            "Epoch 2/20\n",
            "13000/13000 [==============================] - 0s 22us/step - loss: 0.4085 - accuracy: 0.8847 - val_loss: 0.4001 - val_accuracy: 0.8826\n",
            "Epoch 3/20\n",
            "13000/13000 [==============================] - 0s 22us/step - loss: 0.3491 - accuracy: 0.8998 - val_loss: 0.3749 - val_accuracy: 0.8903\n",
            "Epoch 4/20\n",
            "13000/13000 [==============================] - 0s 25us/step - loss: 0.3128 - accuracy: 0.9096 - val_loss: 0.3584 - val_accuracy: 0.8959\n",
            "Epoch 5/20\n",
            "13000/13000 [==============================] - 0s 23us/step - loss: 0.2875 - accuracy: 0.9169 - val_loss: 0.3492 - val_accuracy: 0.9008\n",
            "Epoch 6/20\n",
            "13000/13000 [==============================] - 0s 22us/step - loss: 0.2676 - accuracy: 0.9231 - val_loss: 0.3466 - val_accuracy: 0.8983\n",
            "Epoch 7/20\n",
            "13000/13000 [==============================] - 0s 23us/step - loss: 0.2510 - accuracy: 0.9265 - val_loss: 0.3401 - val_accuracy: 0.9034\n",
            "Epoch 8/20\n",
            "13000/13000 [==============================] - 0s 24us/step - loss: 0.2344 - accuracy: 0.9321 - val_loss: 0.3387 - val_accuracy: 0.9041\n",
            "Epoch 9/20\n",
            "13000/13000 [==============================] - 0s 22us/step - loss: 0.2227 - accuracy: 0.9349 - val_loss: 0.3362 - val_accuracy: 0.9058\n",
            "Epoch 10/20\n",
            "13000/13000 [==============================] - 0s 22us/step - loss: 0.2100 - accuracy: 0.9406 - val_loss: 0.3357 - val_accuracy: 0.9051\n",
            "Epoch 11/20\n",
            "13000/13000 [==============================] - 0s 22us/step - loss: 0.1995 - accuracy: 0.9424 - val_loss: 0.3357 - val_accuracy: 0.9058\n",
            "Epoch 12/20\n",
            "13000/13000 [==============================] - 0s 22us/step - loss: 0.1892 - accuracy: 0.9461 - val_loss: 0.3366 - val_accuracy: 0.9055\n",
            "Epoch 13/20\n",
            "13000/13000 [==============================] - 0s 22us/step - loss: 0.1807 - accuracy: 0.9475 - val_loss: 0.3381 - val_accuracy: 0.9058\n",
            "Epoch 14/20\n",
            "13000/13000 [==============================] - 0s 23us/step - loss: 0.1716 - accuracy: 0.9508 - val_loss: 0.3394 - val_accuracy: 0.9060\n",
            "Epoch 15/20\n",
            "13000/13000 [==============================] - 0s 22us/step - loss: 0.1631 - accuracy: 0.9541 - val_loss: 0.3475 - val_accuracy: 0.9051\n",
            "Epoch 16/20\n",
            "13000/13000 [==============================] - 0s 24us/step - loss: 0.1558 - accuracy: 0.9569 - val_loss: 0.3482 - val_accuracy: 0.9043\n",
            "Epoch 17/20\n",
            "13000/13000 [==============================] - 0s 24us/step - loss: 0.1487 - accuracy: 0.9587 - val_loss: 0.3508 - val_accuracy: 0.9074\n",
            "Epoch 18/20\n",
            "13000/13000 [==============================] - 0s 23us/step - loss: 0.1415 - accuracy: 0.9619 - val_loss: 0.3540 - val_accuracy: 0.9058\n",
            "Epoch 19/20\n",
            "13000/13000 [==============================] - 0s 22us/step - loss: 0.1352 - accuracy: 0.9633 - val_loss: 0.3549 - val_accuracy: 0.9065\n",
            "Epoch 20/20\n",
            "13000/13000 [==============================] - 0s 22us/step - loss: 0.1286 - accuracy: 0.9664 - val_loss: 0.3594 - val_accuracy: 0.9060\n",
            "5724/5724 [==============================] - 0s 22us/step\n",
            "Accuracy: 0.9060097932815552\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v3U6ONn94LXA",
        "colab_type": "text"
      },
      "source": [
        "With Xavier Initialization, One hidden layer with 32 input node, ReLU, Adam, with L1 regularizer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "de7jHrz83AX4",
        "colab_type": "code",
        "outputId": "cac94df9-548d-49e5-b2a9-9bd02cf8446b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "model = get_model(hidden_size=32,regularizers=regularizers.l1(0.01))\n",
        "\n",
        "model.compile(loss='categorical_crossentropy', optimizer='adam',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "model.fit(train_images, train_labels, batch_size=batch_size, epochs=nb_epoch,\n",
        "          verbose=1, validation_data=(test_images, test_labels))\n",
        "\n",
        "score = model.evaluate(test_images, test_labels, verbose=1)\n",
        "\n",
        "print(\"Accuracy:\", score[1])"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model_2\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_2 (InputLayer)         (None, 28, 28, 1)         0         \n",
            "_________________________________________________________________\n",
            "flatten_2 (Flatten)          (None, 784)               0         \n",
            "_________________________________________________________________\n",
            "dense_3 (Dense)              (None, 32)                25120     \n",
            "_________________________________________________________________\n",
            "dense_4 (Dense)              (None, 10)                330       \n",
            "=================================================================\n",
            "Total params: 25,450\n",
            "Trainable params: 25,450\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n",
            "Train on 13000 samples, validate on 5724 samples\n",
            "Epoch 1/20\n",
            "13000/13000 [==============================] - 0s 29us/step - loss: 5.6043 - accuracy: 0.7252 - val_loss: 1.9415 - val_accuracy: 0.8220\n",
            "Epoch 2/20\n",
            "13000/13000 [==============================] - 0s 23us/step - loss: 1.6931 - accuracy: 0.8329 - val_loss: 1.5465 - val_accuracy: 0.8325\n",
            "Epoch 3/20\n",
            "13000/13000 [==============================] - 0s 23us/step - loss: 1.4486 - accuracy: 0.8415 - val_loss: 1.3836 - val_accuracy: 0.8363\n",
            "Epoch 4/20\n",
            "13000/13000 [==============================] - 0s 23us/step - loss: 1.3127 - accuracy: 0.8493 - val_loss: 1.2814 - val_accuracy: 0.8436\n",
            "Epoch 5/20\n",
            "13000/13000 [==============================] - 0s 23us/step - loss: 1.2252 - accuracy: 0.8547 - val_loss: 1.2026 - val_accuracy: 0.8491\n",
            "Epoch 6/20\n",
            "13000/13000 [==============================] - 0s 23us/step - loss: 1.1588 - accuracy: 0.8591 - val_loss: 1.1389 - val_accuracy: 0.8492\n",
            "Epoch 7/20\n",
            "13000/13000 [==============================] - 0s 23us/step - loss: 1.1099 - accuracy: 0.8620 - val_loss: 1.1029 - val_accuracy: 0.8536\n",
            "Epoch 8/20\n",
            "13000/13000 [==============================] - 0s 23us/step - loss: 1.0744 - accuracy: 0.8651 - val_loss: 1.0702 - val_accuracy: 0.8567\n",
            "Epoch 9/20\n",
            "13000/13000 [==============================] - 0s 25us/step - loss: 1.0424 - accuracy: 0.8648 - val_loss: 1.0532 - val_accuracy: 0.8578\n",
            "Epoch 10/20\n",
            "13000/13000 [==============================] - 0s 23us/step - loss: 1.0198 - accuracy: 0.8673 - val_loss: 1.0227 - val_accuracy: 0.8597\n",
            "Epoch 11/20\n",
            "13000/13000 [==============================] - 0s 23us/step - loss: 1.0029 - accuracy: 0.8675 - val_loss: 1.0143 - val_accuracy: 0.8615\n",
            "Epoch 12/20\n",
            "13000/13000 [==============================] - 0s 23us/step - loss: 0.9833 - accuracy: 0.8678 - val_loss: 0.9857 - val_accuracy: 0.8583\n",
            "Epoch 13/20\n",
            "13000/13000 [==============================] - 0s 22us/step - loss: 0.9668 - accuracy: 0.8693 - val_loss: 0.9757 - val_accuracy: 0.8632\n",
            "Epoch 14/20\n",
            "13000/13000 [==============================] - 0s 23us/step - loss: 0.9569 - accuracy: 0.8712 - val_loss: 0.9716 - val_accuracy: 0.8632\n",
            "Epoch 15/20\n",
            "13000/13000 [==============================] - 0s 23us/step - loss: 0.9446 - accuracy: 0.8725 - val_loss: 0.9588 - val_accuracy: 0.8643\n",
            "Epoch 16/20\n",
            "13000/13000 [==============================] - 0s 22us/step - loss: 0.9290 - accuracy: 0.8714 - val_loss: 0.9460 - val_accuracy: 0.8618\n",
            "Epoch 17/20\n",
            "13000/13000 [==============================] - 0s 23us/step - loss: 0.9241 - accuracy: 0.8738 - val_loss: 0.9378 - val_accuracy: 0.8653\n",
            "Epoch 18/20\n",
            "13000/13000 [==============================] - 0s 23us/step - loss: 0.9171 - accuracy: 0.8732 - val_loss: 0.9262 - val_accuracy: 0.8686\n",
            "Epoch 19/20\n",
            "13000/13000 [==============================] - 0s 23us/step - loss: 0.9063 - accuracy: 0.8738 - val_loss: 0.9206 - val_accuracy: 0.8671\n",
            "Epoch 20/20\n",
            "13000/13000 [==============================] - 0s 23us/step - loss: 0.8980 - accuracy: 0.8760 - val_loss: 0.9204 - val_accuracy: 0.8671\n",
            "5724/5724 [==============================] - 0s 20us/step\n",
            "Accuracy: 0.8670510053634644\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IIXS1TtK3KAv",
        "colab_type": "text"
      },
      "source": [
        "With Xavier Initialization, One hidden layer with 32 input node, ReLU, Adam, with L2 regularizer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZVA_LNgA3_I3",
        "colab_type": "code",
        "outputId": "17eed648-3214-45b7-f6c8-71e64f68ce9a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "model = get_model(hidden_size=32,regularizers=regularizers.l2(0.01))\n",
        "\n",
        "model.compile(loss='categorical_crossentropy', optimizer='adam',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "model.fit(train_images, train_labels, batch_size=batch_size, epochs=nb_epoch,\n",
        "          verbose=1, validation_data=(test_images, test_labels))\n",
        "\n",
        "score = model.evaluate(test_images, test_labels, verbose=1)\n",
        "\n",
        "print(\"Accuracy:\", score[1])"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model_3\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_3 (InputLayer)         (None, 28, 28, 1)         0         \n",
            "_________________________________________________________________\n",
            "flatten_3 (Flatten)          (None, 784)               0         \n",
            "_________________________________________________________________\n",
            "dense_5 (Dense)              (None, 32)                25120     \n",
            "_________________________________________________________________\n",
            "dense_6 (Dense)              (None, 10)                330       \n",
            "=================================================================\n",
            "Total params: 25,450\n",
            "Trainable params: 25,450\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n",
            "Train on 13000 samples, validate on 5724 samples\n",
            "Epoch 1/20\n",
            "13000/13000 [==============================] - 0s 28us/step - loss: 1.3771 - accuracy: 0.7658 - val_loss: 0.8928 - val_accuracy: 0.8698\n",
            "Epoch 2/20\n",
            "13000/13000 [==============================] - 0s 22us/step - loss: 0.7362 - accuracy: 0.8797 - val_loss: 0.6475 - val_accuracy: 0.8817\n",
            "Epoch 3/20\n",
            "13000/13000 [==============================] - 0s 22us/step - loss: 0.5751 - accuracy: 0.8903 - val_loss: 0.5546 - val_accuracy: 0.8885\n",
            "Epoch 4/20\n",
            "13000/13000 [==============================] - 0s 23us/step - loss: 0.5092 - accuracy: 0.8967 - val_loss: 0.5205 - val_accuracy: 0.8880\n",
            "Epoch 5/20\n",
            "13000/13000 [==============================] - 0s 23us/step - loss: 0.4757 - accuracy: 0.9000 - val_loss: 0.4971 - val_accuracy: 0.8922\n",
            "Epoch 6/20\n",
            "13000/13000 [==============================] - 0s 22us/step - loss: 0.4551 - accuracy: 0.9022 - val_loss: 0.4853 - val_accuracy: 0.8974\n",
            "Epoch 7/20\n",
            "13000/13000 [==============================] - 0s 24us/step - loss: 0.4438 - accuracy: 0.9043 - val_loss: 0.4709 - val_accuracy: 0.8966\n",
            "Epoch 8/20\n",
            "13000/13000 [==============================] - 0s 23us/step - loss: 0.4304 - accuracy: 0.9065 - val_loss: 0.4737 - val_accuracy: 0.8941\n",
            "Epoch 9/20\n",
            "13000/13000 [==============================] - 0s 22us/step - loss: 0.4199 - accuracy: 0.9084 - val_loss: 0.4586 - val_accuracy: 0.8957\n",
            "Epoch 10/20\n",
            "13000/13000 [==============================] - 0s 23us/step - loss: 0.4112 - accuracy: 0.9099 - val_loss: 0.4574 - val_accuracy: 0.8962\n",
            "Epoch 11/20\n",
            "13000/13000 [==============================] - 0s 22us/step - loss: 0.4052 - accuracy: 0.9099 - val_loss: 0.4484 - val_accuracy: 0.8995\n",
            "Epoch 12/20\n",
            "13000/13000 [==============================] - 0s 23us/step - loss: 0.3973 - accuracy: 0.9118 - val_loss: 0.4441 - val_accuracy: 0.9022\n",
            "Epoch 13/20\n",
            "13000/13000 [==============================] - 0s 25us/step - loss: 0.3925 - accuracy: 0.9141 - val_loss: 0.4392 - val_accuracy: 0.9016\n",
            "Epoch 14/20\n",
            "13000/13000 [==============================] - 0s 25us/step - loss: 0.3873 - accuracy: 0.9137 - val_loss: 0.4322 - val_accuracy: 0.9041\n",
            "Epoch 15/20\n",
            "13000/13000 [==============================] - 0s 23us/step - loss: 0.3833 - accuracy: 0.9156 - val_loss: 0.4495 - val_accuracy: 0.8994\n",
            "Epoch 16/20\n",
            "13000/13000 [==============================] - 0s 22us/step - loss: 0.3829 - accuracy: 0.9142 - val_loss: 0.4341 - val_accuracy: 0.9027\n",
            "Epoch 17/20\n",
            "13000/13000 [==============================] - 0s 24us/step - loss: 0.3750 - accuracy: 0.9161 - val_loss: 0.4401 - val_accuracy: 0.9018\n",
            "Epoch 18/20\n",
            "13000/13000 [==============================] - 0s 23us/step - loss: 0.3713 - accuracy: 0.9183 - val_loss: 0.4277 - val_accuracy: 0.9027\n",
            "Epoch 19/20\n",
            "13000/13000 [==============================] - 0s 23us/step - loss: 0.3690 - accuracy: 0.9188 - val_loss: 0.4361 - val_accuracy: 0.9029\n",
            "Epoch 20/20\n",
            "13000/13000 [==============================] - 0s 22us/step - loss: 0.3683 - accuracy: 0.9198 - val_loss: 0.4365 - val_accuracy: 0.9004\n",
            "5724/5724 [==============================] - 0s 21us/step\n",
            "Accuracy: 0.900419294834137\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "dw2mZ3PL4Vpq"
      },
      "source": [
        "With Xavier Initialization, Two hidden layer with each layer contains 128 input node, ReLU, Adam, without regularizer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "e6c7cf74-d037-4300-f059-525f40d58af1",
        "id": "M1uISYFs4Vpr",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "model = get_model2(hidden_size=128)\n",
        "\n",
        "model.compile(loss='categorical_crossentropy', optimizer='adam',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "model.fit(train_images, train_labels, batch_size=batch_size, epochs=nb_epoch,\n",
        "          verbose=1, validation_data=(test_images, test_labels))\n",
        "\n",
        "score = model.evaluate(test_images, test_labels, verbose=1)\n",
        "\n",
        "print(\"Accuracy:\", score[1])\t  "
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model_4\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_4 (InputLayer)         (None, 28, 28, 1)         0         \n",
            "_________________________________________________________________\n",
            "flatten_4 (Flatten)          (None, 784)               0         \n",
            "_________________________________________________________________\n",
            "dense_7 (Dense)              (None, 128)               100480    \n",
            "_________________________________________________________________\n",
            "dense_8 (Dense)              (None, 128)               16512     \n",
            "_________________________________________________________________\n",
            "dense_9 (Dense)              (None, 10)                1290      \n",
            "=================================================================\n",
            "Total params: 118,282\n",
            "Trainable params: 118,282\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n",
            "Train on 13000 samples, validate on 5724 samples\n",
            "Epoch 1/20\n",
            "13000/13000 [==============================] - 1s 49us/step - loss: 0.6076 - accuracy: 0.8265 - val_loss: 0.3688 - val_accuracy: 0.8901\n",
            "Epoch 2/20\n",
            "13000/13000 [==============================] - 1s 42us/step - loss: 0.2984 - accuracy: 0.9109 - val_loss: 0.3180 - val_accuracy: 0.9064\n",
            "Epoch 3/20\n",
            "13000/13000 [==============================] - 1s 42us/step - loss: 0.2425 - accuracy: 0.9262 - val_loss: 0.3187 - val_accuracy: 0.9065\n",
            "Epoch 4/20\n",
            "13000/13000 [==============================] - 1s 41us/step - loss: 0.2004 - accuracy: 0.9398 - val_loss: 0.3054 - val_accuracy: 0.9132\n",
            "Epoch 5/20\n",
            "13000/13000 [==============================] - 1s 44us/step - loss: 0.1623 - accuracy: 0.9492 - val_loss: 0.3057 - val_accuracy: 0.9137\n",
            "Epoch 6/20\n",
            "13000/13000 [==============================] - 1s 45us/step - loss: 0.1335 - accuracy: 0.9599 - val_loss: 0.3247 - val_accuracy: 0.9133\n",
            "Epoch 7/20\n",
            "13000/13000 [==============================] - 1s 43us/step - loss: 0.1061 - accuracy: 0.9670 - val_loss: 0.3219 - val_accuracy: 0.9154\n",
            "Epoch 8/20\n",
            "13000/13000 [==============================] - 1s 43us/step - loss: 0.0841 - accuracy: 0.9763 - val_loss: 0.3271 - val_accuracy: 0.9165\n",
            "Epoch 9/20\n",
            "13000/13000 [==============================] - 1s 42us/step - loss: 0.0651 - accuracy: 0.9832 - val_loss: 0.3495 - val_accuracy: 0.9167\n",
            "Epoch 10/20\n",
            "13000/13000 [==============================] - 1s 42us/step - loss: 0.0517 - accuracy: 0.9862 - val_loss: 0.3666 - val_accuracy: 0.9163\n",
            "Epoch 11/20\n",
            "13000/13000 [==============================] - 1s 44us/step - loss: 0.0459 - accuracy: 0.9882 - val_loss: 0.3724 - val_accuracy: 0.9174\n",
            "Epoch 12/20\n",
            "13000/13000 [==============================] - 1s 44us/step - loss: 0.0361 - accuracy: 0.9914 - val_loss: 0.3884 - val_accuracy: 0.9175\n",
            "Epoch 13/20\n",
            "13000/13000 [==============================] - 1s 43us/step - loss: 0.0306 - accuracy: 0.9926 - val_loss: 0.4016 - val_accuracy: 0.9170\n",
            "Epoch 14/20\n",
            "13000/13000 [==============================] - 1s 42us/step - loss: 0.0229 - accuracy: 0.9949 - val_loss: 0.4190 - val_accuracy: 0.9147\n",
            "Epoch 15/20\n",
            "13000/13000 [==============================] - 1s 40us/step - loss: 0.0248 - accuracy: 0.9938 - val_loss: 0.4370 - val_accuracy: 0.9161\n",
            "Epoch 16/20\n",
            "13000/13000 [==============================] - 1s 44us/step - loss: 0.0291 - accuracy: 0.9917 - val_loss: 0.4468 - val_accuracy: 0.9144\n",
            "Epoch 17/20\n",
            "13000/13000 [==============================] - 1s 43us/step - loss: 0.0185 - accuracy: 0.9948 - val_loss: 0.4582 - val_accuracy: 0.9158\n",
            "Epoch 18/20\n",
            "13000/13000 [==============================] - 1s 43us/step - loss: 0.0189 - accuracy: 0.9952 - val_loss: 0.4608 - val_accuracy: 0.9147\n",
            "Epoch 19/20\n",
            "13000/13000 [==============================] - 1s 43us/step - loss: 0.0151 - accuracy: 0.9960 - val_loss: 0.4884 - val_accuracy: 0.9142\n",
            "Epoch 20/20\n",
            "13000/13000 [==============================] - 1s 43us/step - loss: 0.0137 - accuracy: 0.9967 - val_loss: 0.4864 - val_accuracy: 0.9144\n",
            "5724/5724 [==============================] - 0s 25us/step\n",
            "Accuracy: 0.9143955111503601\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "Or2DziC74Vpv"
      },
      "source": [
        "With Xavier Initialization, Two hidden layer with each layer contains 128 input node, ReLU, Adam, with L1 regularizer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "FVp1SNIJ4Vpv",
        "outputId": "556c4682-d35b-405d-de2b-8fb574c20c73",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "model = get_model2(hidden_size=128,regularizers=regularizers.l1(0.01))\n",
        "\n",
        "model.compile(loss='categorical_crossentropy', optimizer='adam',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "model.fit(train_images, train_labels, batch_size=batch_size, epochs=nb_epoch,\n",
        "          verbose=1, validation_data=(test_images, test_labels))\n",
        "\n",
        "score = model.evaluate(test_images, test_labels, verbose=1)\n",
        "\n",
        "print(\"Accuracy:\", score[1])"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model_5\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_5 (InputLayer)         (None, 28, 28, 1)         0         \n",
            "_________________________________________________________________\n",
            "flatten_5 (Flatten)          (None, 784)               0         \n",
            "_________________________________________________________________\n",
            "dense_10 (Dense)             (None, 128)               100480    \n",
            "_________________________________________________________________\n",
            "dense_11 (Dense)             (None, 128)               16512     \n",
            "_________________________________________________________________\n",
            "dense_12 (Dense)             (None, 10)                1290      \n",
            "=================================================================\n",
            "Total params: 118,282\n",
            "Trainable params: 118,282\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n",
            "Train on 13000 samples, validate on 5724 samples\n",
            "Epoch 1/20\n",
            "13000/13000 [==============================] - 1s 53us/step - loss: 20.1681 - accuracy: 0.5175 - val_loss: 4.0525 - val_accuracy: 0.4383\n",
            "Epoch 2/20\n",
            "13000/13000 [==============================] - 1s 47us/step - loss: 2.4462 - accuracy: 0.5336 - val_loss: 1.8522 - val_accuracy: 0.6916\n",
            "Epoch 3/20\n",
            "13000/13000 [==============================] - 1s 47us/step - loss: 1.6882 - accuracy: 0.7228 - val_loss: 1.5915 - val_accuracy: 0.7512\n",
            "Epoch 4/20\n",
            "13000/13000 [==============================] - 1s 44us/step - loss: 1.5204 - accuracy: 0.7728 - val_loss: 1.4663 - val_accuracy: 0.7844\n",
            "Epoch 5/20\n",
            "13000/13000 [==============================] - 1s 46us/step - loss: 1.4230 - accuracy: 0.7958 - val_loss: 1.4034 - val_accuracy: 0.8017\n",
            "Epoch 6/20\n",
            "13000/13000 [==============================] - 1s 45us/step - loss: 1.3643 - accuracy: 0.8103 - val_loss: 1.3551 - val_accuracy: 0.8125\n",
            "Epoch 7/20\n",
            "13000/13000 [==============================] - 1s 45us/step - loss: 1.3171 - accuracy: 0.8208 - val_loss: 1.3100 - val_accuracy: 0.8208\n",
            "Epoch 8/20\n",
            "13000/13000 [==============================] - 1s 44us/step - loss: 1.2805 - accuracy: 0.8278 - val_loss: 1.2822 - val_accuracy: 0.8319\n",
            "Epoch 9/20\n",
            "13000/13000 [==============================] - 1s 45us/step - loss: 1.2515 - accuracy: 0.8439 - val_loss: 1.2486 - val_accuracy: 0.8454\n",
            "Epoch 10/20\n",
            "13000/13000 [==============================] - 1s 45us/step - loss: 1.2190 - accuracy: 0.8498 - val_loss: 1.2212 - val_accuracy: 0.8501\n",
            "Epoch 11/20\n",
            "13000/13000 [==============================] - 1s 43us/step - loss: 1.1960 - accuracy: 0.8537 - val_loss: 1.1971 - val_accuracy: 0.8515\n",
            "Epoch 12/20\n",
            "13000/13000 [==============================] - 1s 45us/step - loss: 1.1729 - accuracy: 0.8575 - val_loss: 1.1834 - val_accuracy: 0.8492\n",
            "Epoch 13/20\n",
            "13000/13000 [==============================] - 1s 44us/step - loss: 1.1553 - accuracy: 0.8588 - val_loss: 1.1750 - val_accuracy: 0.8513\n",
            "Epoch 14/20\n",
            "13000/13000 [==============================] - 1s 47us/step - loss: 1.1380 - accuracy: 0.8622 - val_loss: 1.1481 - val_accuracy: 0.8519\n",
            "Epoch 15/20\n",
            "13000/13000 [==============================] - 1s 47us/step - loss: 1.1188 - accuracy: 0.8632 - val_loss: 1.1455 - val_accuracy: 0.8473\n",
            "Epoch 16/20\n",
            "13000/13000 [==============================] - 1s 45us/step - loss: 1.1120 - accuracy: 0.8632 - val_loss: 1.1209 - val_accuracy: 0.8559\n",
            "Epoch 17/20\n",
            "13000/13000 [==============================] - 1s 45us/step - loss: 1.0953 - accuracy: 0.8628 - val_loss: 1.1140 - val_accuracy: 0.8545\n",
            "Epoch 18/20\n",
            "13000/13000 [==============================] - 1s 47us/step - loss: 1.0878 - accuracy: 0.8628 - val_loss: 1.1062 - val_accuracy: 0.8587\n",
            "Epoch 19/20\n",
            "13000/13000 [==============================] - 1s 45us/step - loss: 1.0788 - accuracy: 0.8636 - val_loss: 1.0885 - val_accuracy: 0.8555\n",
            "Epoch 20/20\n",
            "13000/13000 [==============================] - 1s 45us/step - loss: 1.0666 - accuracy: 0.8652 - val_loss: 1.0852 - val_accuracy: 0.8606\n",
            "5724/5724 [==============================] - 0s 31us/step\n",
            "Accuracy: 0.8605870008468628\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "8olj8yk84Vpx"
      },
      "source": [
        "With Xavier Initialization, Two hidden layer with each layer contains 128 input node, ReLU, Adam, with L2\n",
        "regularizer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "EB2LNNNm4Vpy",
        "outputId": "02322316-bde9-4ad7-a6aa-a45e43e60303",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "model = get_model2(hidden_size=128,regularizers=regularizers.l2(0.01))\n",
        "\n",
        "model.compile(loss='categorical_crossentropy', optimizer='adam',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "model.fit(train_images, train_labels, batch_size=batch_size, epochs=nb_epoch,\n",
        "          verbose=1, validation_data=(test_images, test_labels))\n",
        "\n",
        "score = model.evaluate(test_images, test_labels, verbose=1)\n",
        "\n",
        "print(\"Accuracy:\", score[1])"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model_6\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_6 (InputLayer)         (None, 28, 28, 1)         0         \n",
            "_________________________________________________________________\n",
            "flatten_6 (Flatten)          (None, 784)               0         \n",
            "_________________________________________________________________\n",
            "dense_13 (Dense)             (None, 128)               100480    \n",
            "_________________________________________________________________\n",
            "dense_14 (Dense)             (None, 128)               16512     \n",
            "_________________________________________________________________\n",
            "dense_15 (Dense)             (None, 10)                1290      \n",
            "=================================================================\n",
            "Total params: 118,282\n",
            "Trainable params: 118,282\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n",
            "Train on 13000 samples, validate on 5724 samples\n",
            "Epoch 1/20\n",
            "13000/13000 [==============================] - 1s 69us/step - loss: 2.6688 - accuracy: 0.8288 - val_loss: 1.3130 - val_accuracy: 0.8850\n",
            "Epoch 2/20\n",
            "13000/13000 [==============================] - 1s 59us/step - loss: 0.9234 - accuracy: 0.8943 - val_loss: 0.7241 - val_accuracy: 0.8906\n",
            "Epoch 3/20\n",
            "13000/13000 [==============================] - 1s 61us/step - loss: 0.6255 - accuracy: 0.9001 - val_loss: 0.6016 - val_accuracy: 0.8933\n",
            "Epoch 4/20\n",
            "13000/13000 [==============================] - 1s 63us/step - loss: 0.5504 - accuracy: 0.9006 - val_loss: 0.5639 - val_accuracy: 0.8887\n",
            "Epoch 5/20\n",
            "13000/13000 [==============================] - 1s 60us/step - loss: 0.5225 - accuracy: 0.9022 - val_loss: 0.5432 - val_accuracy: 0.8957\n",
            "Epoch 6/20\n",
            "13000/13000 [==============================] - 1s 60us/step - loss: 0.5049 - accuracy: 0.9048 - val_loss: 0.5306 - val_accuracy: 0.8947\n",
            "Epoch 7/20\n",
            "13000/13000 [==============================] - 1s 61us/step - loss: 0.4913 - accuracy: 0.9062 - val_loss: 0.5147 - val_accuracy: 0.8999\n",
            "Epoch 8/20\n",
            "13000/13000 [==============================] - 1s 62us/step - loss: 0.4791 - accuracy: 0.9098 - val_loss: 0.5084 - val_accuracy: 0.8969\n",
            "Epoch 9/20\n",
            "13000/13000 [==============================] - 1s 63us/step - loss: 0.4724 - accuracy: 0.9103 - val_loss: 0.5181 - val_accuracy: 0.8950\n",
            "Epoch 10/20\n",
            "13000/13000 [==============================] - 1s 59us/step - loss: 0.4632 - accuracy: 0.9114 - val_loss: 0.5123 - val_accuracy: 0.8959\n",
            "Epoch 11/20\n",
            "13000/13000 [==============================] - 1s 60us/step - loss: 0.4538 - accuracy: 0.9119 - val_loss: 0.4971 - val_accuracy: 0.9002\n",
            "Epoch 12/20\n",
            "13000/13000 [==============================] - 1s 59us/step - loss: 0.4468 - accuracy: 0.9135 - val_loss: 0.4998 - val_accuracy: 0.8988\n",
            "Epoch 13/20\n",
            "13000/13000 [==============================] - 1s 60us/step - loss: 0.4445 - accuracy: 0.9124 - val_loss: 0.4883 - val_accuracy: 0.9013\n",
            "Epoch 14/20\n",
            "13000/13000 [==============================] - 1s 59us/step - loss: 0.4374 - accuracy: 0.9150 - val_loss: 0.4917 - val_accuracy: 0.9020\n",
            "Epoch 15/20\n",
            "13000/13000 [==============================] - 1s 59us/step - loss: 0.4302 - accuracy: 0.9162 - val_loss: 0.4870 - val_accuracy: 0.9025\n",
            "Epoch 16/20\n",
            "13000/13000 [==============================] - 1s 60us/step - loss: 0.4269 - accuracy: 0.9182 - val_loss: 0.4779 - val_accuracy: 0.9044\n",
            "Epoch 17/20\n",
            "13000/13000 [==============================] - 1s 60us/step - loss: 0.4179 - accuracy: 0.9212 - val_loss: 0.4878 - val_accuracy: 0.9015\n",
            "Epoch 18/20\n",
            "13000/13000 [==============================] - 1s 58us/step - loss: 0.4163 - accuracy: 0.9185 - val_loss: 0.4831 - val_accuracy: 0.9001\n",
            "Epoch 19/20\n",
            "13000/13000 [==============================] - 1s 58us/step - loss: 0.4099 - accuracy: 0.9195 - val_loss: 0.4826 - val_accuracy: 0.8999\n",
            "Epoch 20/20\n",
            "13000/13000 [==============================] - 1s 60us/step - loss: 0.4074 - accuracy: 0.9214 - val_loss: 0.4724 - val_accuracy: 0.9043\n",
            "5724/5724 [==============================] - 0s 28us/step\n",
            "Accuracy: 0.9042627811431885\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "0216p6rE56Xi"
      },
      "source": [
        "With Xavier Initialization, One hidden layer with 32 input node, Swish, Adam, without regularizer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "623dc58e-830b-4fec-c598-2f2b237b6003",
        "id": "yhI0_2oT56Xl",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "model = get_model(hidden_size=32,activation='swish')\n",
        "\n",
        "model.compile(loss='categorical_crossentropy', optimizer='adam',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "model.fit(train_images, train_labels, batch_size=batch_size, epochs=nb_epoch,\n",
        "          verbose=1, validation_data=(test_images, test_labels))\n",
        "\n",
        "score = model.evaluate(test_images, test_labels, verbose=1)\n",
        "\n",
        "print(\"Accuracy:\", score[1])\t  "
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model_7\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_7 (InputLayer)         (None, 28, 28, 1)         0         \n",
            "_________________________________________________________________\n",
            "flatten_7 (Flatten)          (None, 784)               0         \n",
            "_________________________________________________________________\n",
            "dense_16 (Dense)             (None, 32)                25120     \n",
            "_________________________________________________________________\n",
            "dense_17 (Dense)             (None, 10)                330       \n",
            "=================================================================\n",
            "Total params: 25,450\n",
            "Trainable params: 25,450\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n",
            "Train on 13000 samples, validate on 5724 samples\n",
            "Epoch 1/20\n",
            "13000/13000 [==============================] - 0s 33us/step - loss: 0.7802 - accuracy: 0.7971 - val_loss: 0.4725 - val_accuracy: 0.8677\n",
            "Epoch 2/20\n",
            "13000/13000 [==============================] - 0s 29us/step - loss: 0.4101 - accuracy: 0.8852 - val_loss: 0.4048 - val_accuracy: 0.8835\n",
            "Epoch 3/20\n",
            "13000/13000 [==============================] - 0s 27us/step - loss: 0.3486 - accuracy: 0.8978 - val_loss: 0.3723 - val_accuracy: 0.8913\n",
            "Epoch 4/20\n",
            "13000/13000 [==============================] - 0s 27us/step - loss: 0.3118 - accuracy: 0.9087 - val_loss: 0.3591 - val_accuracy: 0.8952\n",
            "Epoch 5/20\n",
            "13000/13000 [==============================] - 0s 26us/step - loss: 0.2843 - accuracy: 0.9153 - val_loss: 0.3457 - val_accuracy: 0.8995\n",
            "Epoch 6/20\n",
            "13000/13000 [==============================] - 0s 26us/step - loss: 0.2627 - accuracy: 0.9221 - val_loss: 0.3393 - val_accuracy: 0.9016\n",
            "Epoch 7/20\n",
            "13000/13000 [==============================] - 0s 26us/step - loss: 0.2439 - accuracy: 0.9273 - val_loss: 0.3362 - val_accuracy: 0.9041\n",
            "Epoch 8/20\n",
            "13000/13000 [==============================] - 0s 26us/step - loss: 0.2279 - accuracy: 0.9308 - val_loss: 0.3311 - val_accuracy: 0.9051\n",
            "Epoch 9/20\n",
            "13000/13000 [==============================] - 0s 27us/step - loss: 0.2125 - accuracy: 0.9370 - val_loss: 0.3309 - val_accuracy: 0.9065\n",
            "Epoch 10/20\n",
            "13000/13000 [==============================] - 0s 29us/step - loss: 0.1995 - accuracy: 0.9418 - val_loss: 0.3298 - val_accuracy: 0.9092\n",
            "Epoch 11/20\n",
            "13000/13000 [==============================] - 0s 28us/step - loss: 0.1883 - accuracy: 0.9454 - val_loss: 0.3308 - val_accuracy: 0.9093\n",
            "Epoch 12/20\n",
            "13000/13000 [==============================] - 0s 29us/step - loss: 0.1772 - accuracy: 0.9484 - val_loss: 0.3338 - val_accuracy: 0.9088\n",
            "Epoch 13/20\n",
            "13000/13000 [==============================] - 0s 28us/step - loss: 0.1681 - accuracy: 0.9512 - val_loss: 0.3356 - val_accuracy: 0.9090\n",
            "Epoch 14/20\n",
            "13000/13000 [==============================] - 0s 27us/step - loss: 0.1593 - accuracy: 0.9548 - val_loss: 0.3356 - val_accuracy: 0.9081\n",
            "Epoch 15/20\n",
            "13000/13000 [==============================] - 0s 25us/step - loss: 0.1498 - accuracy: 0.9574 - val_loss: 0.3427 - val_accuracy: 0.9058\n",
            "Epoch 16/20\n",
            "13000/13000 [==============================] - 0s 26us/step - loss: 0.1409 - accuracy: 0.9608 - val_loss: 0.3476 - val_accuracy: 0.9069\n",
            "Epoch 17/20\n",
            "13000/13000 [==============================] - 0s 25us/step - loss: 0.1336 - accuracy: 0.9628 - val_loss: 0.3463 - val_accuracy: 0.9090\n",
            "Epoch 18/20\n",
            "13000/13000 [==============================] - 0s 26us/step - loss: 0.1261 - accuracy: 0.9650 - val_loss: 0.3540 - val_accuracy: 0.9074\n",
            "Epoch 19/20\n",
            "13000/13000 [==============================] - 0s 25us/step - loss: 0.1209 - accuracy: 0.9665 - val_loss: 0.3583 - val_accuracy: 0.9088\n",
            "Epoch 20/20\n",
            "13000/13000 [==============================] - 0s 26us/step - loss: 0.1138 - accuracy: 0.9694 - val_loss: 0.3651 - val_accuracy: 0.9065\n",
            "5724/5724 [==============================] - 0s 22us/step\n",
            "Accuracy: 0.9065338969230652\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "-m_pB7ak56Xp"
      },
      "source": [
        "With Xavier Initialization, One hidden layer with 32 input node, Swish, Adam, with L1 regularizer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "M6oQE6iD56Xp",
        "outputId": "7aa8e025-f779-4f72-b309-6df31ed2946a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "model = get_model(hidden_size=32,activation='swish',regularizers=regularizers.l1(0.01))\n",
        "\n",
        "model.compile(loss='categorical_crossentropy', optimizer='adam',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "model.fit(train_images, train_labels, batch_size=batch_size, epochs=nb_epoch,\n",
        "          verbose=1, validation_data=(test_images, test_labels))\n",
        "\n",
        "score = model.evaluate(test_images, test_labels, verbose=1)\n",
        "\n",
        "print(\"Accuracy:\", score[1])"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model_8\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_8 (InputLayer)         (None, 28, 28, 1)         0         \n",
            "_________________________________________________________________\n",
            "flatten_8 (Flatten)          (None, 784)               0         \n",
            "_________________________________________________________________\n",
            "dense_18 (Dense)             (None, 32)                25120     \n",
            "_________________________________________________________________\n",
            "dense_19 (Dense)             (None, 10)                330       \n",
            "=================================================================\n",
            "Total params: 25,450\n",
            "Trainable params: 25,450\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n",
            "Train on 13000 samples, validate on 5724 samples\n",
            "Epoch 1/20\n",
            "13000/13000 [==============================] - 0s 33us/step - loss: 5.5241 - accuracy: 0.7202 - val_loss: 1.9242 - val_accuracy: 0.8103\n",
            "Epoch 2/20\n",
            "13000/13000 [==============================] - 0s 27us/step - loss: 1.6882 - accuracy: 0.8173 - val_loss: 1.5619 - val_accuracy: 0.8176\n",
            "Epoch 3/20\n",
            "13000/13000 [==============================] - 0s 27us/step - loss: 1.4562 - accuracy: 0.8340 - val_loss: 1.3933 - val_accuracy: 0.8304\n",
            "Epoch 4/20\n",
            "13000/13000 [==============================] - 0s 26us/step - loss: 1.3153 - accuracy: 0.8464 - val_loss: 1.2792 - val_accuracy: 0.8438\n",
            "Epoch 5/20\n",
            "13000/13000 [==============================] - 0s 27us/step - loss: 1.2179 - accuracy: 0.8545 - val_loss: 1.1983 - val_accuracy: 0.8461\n",
            "Epoch 6/20\n",
            "13000/13000 [==============================] - 0s 25us/step - loss: 1.1479 - accuracy: 0.8578 - val_loss: 1.1417 - val_accuracy: 0.8489\n",
            "Epoch 7/20\n",
            "13000/13000 [==============================] - 0s 27us/step - loss: 1.0975 - accuracy: 0.8585 - val_loss: 1.1015 - val_accuracy: 0.8505\n",
            "Epoch 8/20\n",
            "13000/13000 [==============================] - 0s 29us/step - loss: 1.0592 - accuracy: 0.8579 - val_loss: 1.0608 - val_accuracy: 0.8517\n",
            "Epoch 9/20\n",
            "13000/13000 [==============================] - 0s 26us/step - loss: 1.0281 - accuracy: 0.8614 - val_loss: 1.0375 - val_accuracy: 0.8503\n",
            "Epoch 10/20\n",
            "13000/13000 [==============================] - 0s 27us/step - loss: 1.0001 - accuracy: 0.8636 - val_loss: 1.0125 - val_accuracy: 0.8559\n",
            "Epoch 11/20\n",
            "13000/13000 [==============================] - 0s 26us/step - loss: 0.9760 - accuracy: 0.8654 - val_loss: 0.9875 - val_accuracy: 0.8543\n",
            "Epoch 12/20\n",
            "13000/13000 [==============================] - 0s 26us/step - loss: 0.9600 - accuracy: 0.8648 - val_loss: 0.9729 - val_accuracy: 0.8557\n",
            "Epoch 13/20\n",
            "13000/13000 [==============================] - 0s 27us/step - loss: 0.9425 - accuracy: 0.8666 - val_loss: 0.9612 - val_accuracy: 0.8604\n",
            "Epoch 14/20\n",
            "13000/13000 [==============================] - 0s 25us/step - loss: 0.9277 - accuracy: 0.8699 - val_loss: 0.9406 - val_accuracy: 0.8588\n",
            "Epoch 15/20\n",
            "13000/13000 [==============================] - 0s 26us/step - loss: 0.9163 - accuracy: 0.8679 - val_loss: 0.9295 - val_accuracy: 0.8611\n",
            "Epoch 16/20\n",
            "13000/13000 [==============================] - 0s 27us/step - loss: 0.9058 - accuracy: 0.8704 - val_loss: 0.9333 - val_accuracy: 0.8574\n",
            "Epoch 17/20\n",
            "13000/13000 [==============================] - 0s 26us/step - loss: 0.8996 - accuracy: 0.8698 - val_loss: 0.9176 - val_accuracy: 0.8630\n",
            "Epoch 18/20\n",
            "13000/13000 [==============================] - 0s 26us/step - loss: 0.8879 - accuracy: 0.8724 - val_loss: 0.8991 - val_accuracy: 0.8643\n",
            "Epoch 19/20\n",
            "13000/13000 [==============================] - 0s 27us/step - loss: 0.8802 - accuracy: 0.8719 - val_loss: 0.9014 - val_accuracy: 0.8585\n",
            "Epoch 20/20\n",
            "13000/13000 [==============================] - 0s 26us/step - loss: 0.8717 - accuracy: 0.8732 - val_loss: 0.9079 - val_accuracy: 0.8597\n",
            "5724/5724 [==============================] - 0s 23us/step\n",
            "Accuracy: 0.8597134947776794\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "5nFtO2cm56Xr"
      },
      "source": [
        "With Xavier Initialization, One hidden layer with 32 input node, Swish, Adam, with L2 regularizer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "gJcSOpZH56Xr",
        "outputId": "35f4259d-1b75-467a-a196-f39bffeb61b5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "model = get_model(hidden_size=32,activation='swish',regularizers=regularizers.l2(0.01))\n",
        "\n",
        "model.compile(loss='categorical_crossentropy', optimizer='adam',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "model.fit(train_images, train_labels, batch_size=batch_size, epochs=nb_epoch,\n",
        "          verbose=1, validation_data=(test_images, test_labels))\n",
        "\n",
        "score = model.evaluate(test_images, test_labels, verbose=1)\n",
        "\n",
        "print(\"Accuracy:\", score[1])"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model_9\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_9 (InputLayer)         (None, 28, 28, 1)         0         \n",
            "_________________________________________________________________\n",
            "flatten_9 (Flatten)          (None, 784)               0         \n",
            "_________________________________________________________________\n",
            "dense_20 (Dense)             (None, 32)                25120     \n",
            "_________________________________________________________________\n",
            "dense_21 (Dense)             (None, 10)                330       \n",
            "=================================================================\n",
            "Total params: 25,450\n",
            "Trainable params: 25,450\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n",
            "Train on 13000 samples, validate on 5724 samples\n",
            "Epoch 1/20\n",
            "13000/13000 [==============================] - 0s 34us/step - loss: 1.3805 - accuracy: 0.7671 - val_loss: 0.8891 - val_accuracy: 0.8679\n",
            "Epoch 2/20\n",
            "13000/13000 [==============================] - 0s 26us/step - loss: 0.7302 - accuracy: 0.8825 - val_loss: 0.6461 - val_accuracy: 0.8810\n",
            "Epoch 3/20\n",
            "13000/13000 [==============================] - 0s 26us/step - loss: 0.5727 - accuracy: 0.8948 - val_loss: 0.5557 - val_accuracy: 0.8898\n",
            "Epoch 4/20\n",
            "13000/13000 [==============================] - 0s 26us/step - loss: 0.5122 - accuracy: 0.8995 - val_loss: 0.5216 - val_accuracy: 0.8892\n",
            "Epoch 5/20\n",
            "13000/13000 [==============================] - 0s 26us/step - loss: 0.4812 - accuracy: 0.9005 - val_loss: 0.5001 - val_accuracy: 0.8936\n",
            "Epoch 6/20\n",
            "13000/13000 [==============================] - 0s 26us/step - loss: 0.4635 - accuracy: 0.9045 - val_loss: 0.4916 - val_accuracy: 0.8924\n",
            "Epoch 7/20\n",
            "13000/13000 [==============================] - 0s 28us/step - loss: 0.4525 - accuracy: 0.9041 - val_loss: 0.4798 - val_accuracy: 0.8945\n",
            "Epoch 8/20\n",
            "13000/13000 [==============================] - 0s 26us/step - loss: 0.4416 - accuracy: 0.9057 - val_loss: 0.4758 - val_accuracy: 0.8927\n",
            "Epoch 9/20\n",
            "13000/13000 [==============================] - 0s 26us/step - loss: 0.4335 - accuracy: 0.9091 - val_loss: 0.4723 - val_accuracy: 0.8955\n",
            "Epoch 10/20\n",
            "13000/13000 [==============================] - 0s 25us/step - loss: 0.4268 - accuracy: 0.9089 - val_loss: 0.4651 - val_accuracy: 0.8968\n",
            "Epoch 11/20\n",
            "13000/13000 [==============================] - 0s 27us/step - loss: 0.4217 - accuracy: 0.9091 - val_loss: 0.4582 - val_accuracy: 0.8968\n",
            "Epoch 12/20\n",
            "13000/13000 [==============================] - 0s 26us/step - loss: 0.4132 - accuracy: 0.9105 - val_loss: 0.4528 - val_accuracy: 0.8992\n",
            "Epoch 13/20\n",
            "13000/13000 [==============================] - 0s 26us/step - loss: 0.4113 - accuracy: 0.9118 - val_loss: 0.4498 - val_accuracy: 0.8983\n",
            "Epoch 14/20\n",
            "13000/13000 [==============================] - 0s 25us/step - loss: 0.4045 - accuracy: 0.9137 - val_loss: 0.4511 - val_accuracy: 0.8988\n",
            "Epoch 15/20\n",
            "13000/13000 [==============================] - 0s 26us/step - loss: 0.4016 - accuracy: 0.9123 - val_loss: 0.4415 - val_accuracy: 0.9025\n",
            "Epoch 16/20\n",
            "13000/13000 [==============================] - 0s 25us/step - loss: 0.3975 - accuracy: 0.9115 - val_loss: 0.4449 - val_accuracy: 0.8981\n",
            "Epoch 17/20\n",
            "13000/13000 [==============================] - 0s 25us/step - loss: 0.3943 - accuracy: 0.9137 - val_loss: 0.4425 - val_accuracy: 0.8981\n",
            "Epoch 18/20\n",
            "13000/13000 [==============================] - 0s 25us/step - loss: 0.3908 - accuracy: 0.9140 - val_loss: 0.4396 - val_accuracy: 0.9006\n",
            "Epoch 19/20\n",
            "13000/13000 [==============================] - 0s 25us/step - loss: 0.3863 - accuracy: 0.9170 - val_loss: 0.4355 - val_accuracy: 0.9018\n",
            "Epoch 20/20\n",
            "13000/13000 [==============================] - 0s 26us/step - loss: 0.3880 - accuracy: 0.9145 - val_loss: 0.4504 - val_accuracy: 0.8988\n",
            "5724/5724 [==============================] - 0s 23us/step\n",
            "Accuracy: 0.8988469839096069\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "3YmrB4Ep56Xt"
      },
      "source": [
        "With Xavier Initialization, Two hidden layer with each layer contains 128 input node, Swish, Adam, without regularizer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "73747965-20a0-45b9-ad0e-f45acbf482de",
        "id": "nOLarrTa56Xt",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "model = get_model2(hidden_size=128,activation='swish')\n",
        "\n",
        "model.compile(loss='categorical_crossentropy', optimizer='adam',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "model.fit(train_images, train_labels, batch_size=batch_size, epochs=nb_epoch,\n",
        "          verbose=1, validation_data=(test_images, test_labels))\n",
        "\n",
        "score = model.evaluate(test_images, test_labels, verbose=1)\n",
        "\n",
        "print(\"Accuracy:\", score[1])\t  "
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model_10\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_10 (InputLayer)        (None, 28, 28, 1)         0         \n",
            "_________________________________________________________________\n",
            "flatten_10 (Flatten)         (None, 784)               0         \n",
            "_________________________________________________________________\n",
            "dense_22 (Dense)             (None, 128)               100480    \n",
            "_________________________________________________________________\n",
            "dense_23 (Dense)             (None, 128)               16512     \n",
            "_________________________________________________________________\n",
            "dense_24 (Dense)             (None, 10)                1290      \n",
            "=================================================================\n",
            "Total params: 118,282\n",
            "Trainable params: 118,282\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n",
            "Train on 13000 samples, validate on 5724 samples\n",
            "Epoch 1/20\n",
            "13000/13000 [==============================] - 1s 54us/step - loss: 0.5835 - accuracy: 0.8352 - val_loss: 0.3690 - val_accuracy: 0.8885\n",
            "Epoch 2/20\n",
            "13000/13000 [==============================] - 1s 47us/step - loss: 0.3025 - accuracy: 0.9085 - val_loss: 0.3250 - val_accuracy: 0.9050\n",
            "Epoch 3/20\n",
            "13000/13000 [==============================] - 1s 42us/step - loss: 0.2478 - accuracy: 0.9251 - val_loss: 0.3098 - val_accuracy: 0.9107\n",
            "Epoch 4/20\n",
            "13000/13000 [==============================] - 1s 42us/step - loss: 0.2000 - accuracy: 0.9368 - val_loss: 0.2981 - val_accuracy: 0.9153\n",
            "Epoch 5/20\n",
            "13000/13000 [==============================] - 1s 44us/step - loss: 0.1644 - accuracy: 0.9475 - val_loss: 0.3094 - val_accuracy: 0.9139\n",
            "Epoch 6/20\n",
            "13000/13000 [==============================] - 1s 42us/step - loss: 0.1343 - accuracy: 0.9571 - val_loss: 0.3174 - val_accuracy: 0.9165\n",
            "Epoch 7/20\n",
            "13000/13000 [==============================] - 1s 42us/step - loss: 0.1097 - accuracy: 0.9655 - val_loss: 0.3269 - val_accuracy: 0.9172\n",
            "Epoch 8/20\n",
            "13000/13000 [==============================] - 1s 43us/step - loss: 0.0888 - accuracy: 0.9725 - val_loss: 0.3403 - val_accuracy: 0.9196\n",
            "Epoch 9/20\n",
            "13000/13000 [==============================] - 1s 43us/step - loss: 0.0694 - accuracy: 0.9799 - val_loss: 0.3790 - val_accuracy: 0.9111\n",
            "Epoch 10/20\n",
            "13000/13000 [==============================] - 1s 45us/step - loss: 0.0553 - accuracy: 0.9844 - val_loss: 0.3870 - val_accuracy: 0.9179\n",
            "Epoch 11/20\n",
            "13000/13000 [==============================] - 1s 43us/step - loss: 0.0446 - accuracy: 0.9872 - val_loss: 0.3911 - val_accuracy: 0.9200\n",
            "Epoch 12/20\n",
            "13000/13000 [==============================] - 1s 42us/step - loss: 0.0339 - accuracy: 0.9907 - val_loss: 0.4217 - val_accuracy: 0.9182\n",
            "Epoch 13/20\n",
            "13000/13000 [==============================] - 1s 41us/step - loss: 0.0305 - accuracy: 0.9918 - val_loss: 0.4426 - val_accuracy: 0.9191\n",
            "Epoch 14/20\n",
            "13000/13000 [==============================] - 1s 43us/step - loss: 0.0287 - accuracy: 0.9927 - val_loss: 0.4546 - val_accuracy: 0.9156\n",
            "Epoch 15/20\n",
            "13000/13000 [==============================] - 1s 43us/step - loss: 0.0231 - accuracy: 0.9939 - val_loss: 0.4735 - val_accuracy: 0.9189\n",
            "Epoch 16/20\n",
            "13000/13000 [==============================] - 1s 43us/step - loss: 0.0251 - accuracy: 0.9922 - val_loss: 0.4875 - val_accuracy: 0.9153\n",
            "Epoch 17/20\n",
            "13000/13000 [==============================] - 1s 43us/step - loss: 0.0292 - accuracy: 0.9916 - val_loss: 0.4914 - val_accuracy: 0.9167\n",
            "Epoch 18/20\n",
            "13000/13000 [==============================] - 1s 42us/step - loss: 0.0156 - accuracy: 0.9951 - val_loss: 0.4904 - val_accuracy: 0.9237\n",
            "Epoch 19/20\n",
            "13000/13000 [==============================] - 1s 46us/step - loss: 0.0144 - accuracy: 0.9965 - val_loss: 0.5322 - val_accuracy: 0.9198\n",
            "Epoch 20/20\n",
            "13000/13000 [==============================] - 1s 42us/step - loss: 0.0134 - accuracy: 0.9962 - val_loss: 0.5262 - val_accuracy: 0.9212\n",
            "5724/5724 [==============================] - 0s 26us/step\n",
            "Accuracy: 0.921208918094635\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "kpldpsbZ56Xv"
      },
      "source": [
        "With Xavier Initialization, Two hidden layer with each layer contains 128 input node, Swish, Adam, with L1 regularizer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "N-yd-IRQ56Xv",
        "outputId": "0bd82cc8-dd87-48e0-ec4d-c98614da6abf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "model = get_model2(hidden_size=128,regularizers=regularizers.l1(0.01))\n",
        "\n",
        "model.compile(loss='categorical_crossentropy', optimizer='adam',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "model.fit(train_images, train_labels, batch_size=batch_size, epochs=nb_epoch,\n",
        "          verbose=1, validation_data=(test_images, test_labels))\n",
        "\n",
        "score = model.evaluate(test_images, test_labels, verbose=1)\n",
        "\n",
        "print(\"Accuracy:\", score[1])"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model_11\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_11 (InputLayer)        (None, 28, 28, 1)         0         \n",
            "_________________________________________________________________\n",
            "flatten_11 (Flatten)         (None, 784)               0         \n",
            "_________________________________________________________________\n",
            "dense_25 (Dense)             (None, 128)               100480    \n",
            "_________________________________________________________________\n",
            "dense_26 (Dense)             (None, 128)               16512     \n",
            "_________________________________________________________________\n",
            "dense_27 (Dense)             (None, 10)                1290      \n",
            "=================================================================\n",
            "Total params: 118,282\n",
            "Trainable params: 118,282\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n",
            "Train on 13000 samples, validate on 5724 samples\n",
            "Epoch 1/20\n",
            "13000/13000 [==============================] - 1s 63us/step - loss: 20.5431 - accuracy: 0.4525 - val_loss: 4.1586 - val_accuracy: 0.3726\n",
            "Epoch 2/20\n",
            "13000/13000 [==============================] - 1s 56us/step - loss: 2.4692 - accuracy: 0.4202 - val_loss: 1.8955 - val_accuracy: 0.4792\n",
            "Epoch 3/20\n",
            "13000/13000 [==============================] - 1s 51us/step - loss: 1.7680 - accuracy: 0.5394 - val_loss: 1.7191 - val_accuracy: 0.5772\n",
            "Epoch 4/20\n",
            "13000/13000 [==============================] - 1s 53us/step - loss: 1.6321 - accuracy: 0.6217 - val_loss: 1.6098 - val_accuracy: 0.6237\n",
            "Epoch 5/20\n",
            "13000/13000 [==============================] - 1s 54us/step - loss: 1.5392 - accuracy: 0.6599 - val_loss: 1.5392 - val_accuracy: 0.6431\n",
            "Epoch 6/20\n",
            "13000/13000 [==============================] - 1s 52us/step - loss: 1.4763 - accuracy: 0.6916 - val_loss: 1.4732 - val_accuracy: 0.6873\n",
            "Epoch 7/20\n",
            "13000/13000 [==============================] - 1s 56us/step - loss: 1.4155 - accuracy: 0.7322 - val_loss: 1.4146 - val_accuracy: 0.7427\n",
            "Epoch 8/20\n",
            "13000/13000 [==============================] - 1s 52us/step - loss: 1.3735 - accuracy: 0.7441 - val_loss: 1.3737 - val_accuracy: 0.7498\n",
            "Epoch 9/20\n",
            "13000/13000 [==============================] - 1s 53us/step - loss: 1.3344 - accuracy: 0.7609 - val_loss: 1.3517 - val_accuracy: 0.7614\n",
            "Epoch 10/20\n",
            "13000/13000 [==============================] - 1s 52us/step - loss: 1.3047 - accuracy: 0.7719 - val_loss: 1.3174 - val_accuracy: 0.7687\n",
            "Epoch 11/20\n",
            "13000/13000 [==============================] - 1s 53us/step - loss: 1.2772 - accuracy: 0.7813 - val_loss: 1.2915 - val_accuracy: 0.7767\n",
            "Epoch 12/20\n",
            "13000/13000 [==============================] - 1s 54us/step - loss: 1.2515 - accuracy: 0.7902 - val_loss: 1.2837 - val_accuracy: 0.7757\n",
            "Epoch 13/20\n",
            "13000/13000 [==============================] - 1s 54us/step - loss: 1.2394 - accuracy: 0.7889 - val_loss: 1.2686 - val_accuracy: 0.7877\n",
            "Epoch 14/20\n",
            "13000/13000 [==============================] - 1s 51us/step - loss: 1.2248 - accuracy: 0.7971 - val_loss: 1.2509 - val_accuracy: 0.7874\n",
            "Epoch 15/20\n",
            "13000/13000 [==============================] - 1s 51us/step - loss: 1.2167 - accuracy: 0.7964 - val_loss: 1.2335 - val_accuracy: 0.8010\n",
            "Epoch 16/20\n",
            "13000/13000 [==============================] - 1s 54us/step - loss: 1.1984 - accuracy: 0.8045 - val_loss: 1.2332 - val_accuracy: 0.7926\n",
            "Epoch 17/20\n",
            "13000/13000 [==============================] - 1s 55us/step - loss: 1.1923 - accuracy: 0.8042 - val_loss: 1.2187 - val_accuracy: 0.8022\n",
            "Epoch 18/20\n",
            "13000/13000 [==============================] - 1s 53us/step - loss: 1.1818 - accuracy: 0.8075 - val_loss: 1.2144 - val_accuracy: 0.7989\n",
            "Epoch 19/20\n",
            "13000/13000 [==============================] - 1s 53us/step - loss: 1.1799 - accuracy: 0.8052 - val_loss: 1.2082 - val_accuracy: 0.8054\n",
            "Epoch 20/20\n",
            "13000/13000 [==============================] - 1s 53us/step - loss: 1.1694 - accuracy: 0.8071 - val_loss: 1.1982 - val_accuracy: 0.8089\n",
            "5724/5724 [==============================] - 0s 30us/step\n",
            "Accuracy: 0.8088749051094055\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "EI_ugAky56Xx"
      },
      "source": [
        "With Xavier Initialization, Two hidden layer with each layer contains 128 input node, Swish, Adam, with L2\n",
        "regularizer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "E30bQUIi56Xy",
        "outputId": "8014fec8-9e2e-4153-f810-8ed18f22645b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "model = get_model2(hidden_size=128,regularizers=regularizers.l2(0.01))\n",
        "\n",
        "model.compile(loss='categorical_crossentropy', optimizer='adam',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "model.fit(train_images, train_labels, batch_size=batch_size, epochs=nb_epoch,\n",
        "          verbose=1, validation_data=(test_images, test_labels))\n",
        "\n",
        "score = model.evaluate(test_images, test_labels, verbose=1)\n",
        "\n",
        "print(\"Accuracy:\", score[1])"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model_12\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_12 (InputLayer)        (None, 28, 28, 1)         0         \n",
            "_________________________________________________________________\n",
            "flatten_12 (Flatten)         (None, 784)               0         \n",
            "_________________________________________________________________\n",
            "dense_28 (Dense)             (None, 128)               100480    \n",
            "_________________________________________________________________\n",
            "dense_29 (Dense)             (None, 128)               16512     \n",
            "_________________________________________________________________\n",
            "dense_30 (Dense)             (None, 10)                1290      \n",
            "=================================================================\n",
            "Total params: 118,282\n",
            "Trainable params: 118,282\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n",
            "Train on 13000 samples, validate on 5724 samples\n",
            "Epoch 1/20\n",
            "13000/13000 [==============================] - 1s 63us/step - loss: 2.6275 - accuracy: 0.8269 - val_loss: 1.2681 - val_accuracy: 0.8842\n",
            "Epoch 2/20\n",
            "13000/13000 [==============================] - 1s 57us/step - loss: 0.8983 - accuracy: 0.8957 - val_loss: 0.7011 - val_accuracy: 0.8910\n",
            "Epoch 3/20\n",
            "13000/13000 [==============================] - 1s 59us/step - loss: 0.6154 - accuracy: 0.8997 - val_loss: 0.5914 - val_accuracy: 0.8943\n",
            "Epoch 4/20\n",
            "13000/13000 [==============================] - 1s 56us/step - loss: 0.5488 - accuracy: 0.9019 - val_loss: 0.5523 - val_accuracy: 0.8971\n",
            "Epoch 5/20\n",
            "13000/13000 [==============================] - 1s 55us/step - loss: 0.5229 - accuracy: 0.9040 - val_loss: 0.5389 - val_accuracy: 0.8959\n",
            "Epoch 6/20\n",
            "13000/13000 [==============================] - 1s 58us/step - loss: 0.5043 - accuracy: 0.9050 - val_loss: 0.5322 - val_accuracy: 0.8962\n",
            "Epoch 7/20\n",
            "13000/13000 [==============================] - 1s 59us/step - loss: 0.4895 - accuracy: 0.9077 - val_loss: 0.5201 - val_accuracy: 0.8983\n",
            "Epoch 8/20\n",
            "13000/13000 [==============================] - 1s 56us/step - loss: 0.4802 - accuracy: 0.9085 - val_loss: 0.5168 - val_accuracy: 0.8969\n",
            "Epoch 9/20\n",
            "13000/13000 [==============================] - 1s 56us/step - loss: 0.4712 - accuracy: 0.9095 - val_loss: 0.5185 - val_accuracy: 0.8969\n",
            "Epoch 10/20\n",
            "13000/13000 [==============================] - 1s 55us/step - loss: 0.4641 - accuracy: 0.9100 - val_loss: 0.5097 - val_accuracy: 0.8985\n",
            "Epoch 11/20\n",
            "13000/13000 [==============================] - 1s 57us/step - loss: 0.4555 - accuracy: 0.9142 - val_loss: 0.4912 - val_accuracy: 0.9006\n",
            "Epoch 12/20\n",
            "13000/13000 [==============================] - 1s 57us/step - loss: 0.4533 - accuracy: 0.9123 - val_loss: 0.5017 - val_accuracy: 0.8952\n",
            "Epoch 13/20\n",
            "13000/13000 [==============================] - 1s 58us/step - loss: 0.4429 - accuracy: 0.9152 - val_loss: 0.5166 - val_accuracy: 0.8936\n",
            "Epoch 14/20\n",
            "13000/13000 [==============================] - 1s 57us/step - loss: 0.4412 - accuracy: 0.9136 - val_loss: 0.4992 - val_accuracy: 0.8987\n",
            "Epoch 15/20\n",
            "13000/13000 [==============================] - 1s 57us/step - loss: 0.4298 - accuracy: 0.9164 - val_loss: 0.4876 - val_accuracy: 0.9008\n",
            "Epoch 16/20\n",
            "13000/13000 [==============================] - 1s 58us/step - loss: 0.4277 - accuracy: 0.9171 - val_loss: 0.4797 - val_accuracy: 0.9057\n",
            "Epoch 17/20\n",
            "13000/13000 [==============================] - 1s 57us/step - loss: 0.4218 - accuracy: 0.9189 - val_loss: 0.4728 - val_accuracy: 0.9097\n",
            "Epoch 18/20\n",
            "13000/13000 [==============================] - 1s 57us/step - loss: 0.4166 - accuracy: 0.9213 - val_loss: 0.4856 - val_accuracy: 0.9004\n",
            "Epoch 19/20\n",
            "13000/13000 [==============================] - 1s 57us/step - loss: 0.4193 - accuracy: 0.9182 - val_loss: 0.4811 - val_accuracy: 0.9048\n",
            "Epoch 20/20\n",
            "13000/13000 [==============================] - 1s 54us/step - loss: 0.4107 - accuracy: 0.9215 - val_loss: 0.4687 - val_accuracy: 0.9085\n",
            "5724/5724 [==============================] - 0s 29us/step\n",
            "Accuracy: 0.9084556102752686\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F29jFmyHkoHo",
        "colab_type": "text"
      },
      "source": [
        "To save the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GzllSm3SS292",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.save(\"model.h5\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R-lghkijkrzP",
        "colab_type": "text"
      },
      "source": [
        "To load the model and run inference"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1l6x0MXsUz1a",
        "colab_type": "code",
        "outputId": "7bba6a5c-ff08-4c9e-fb18-829c9d2881ed",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 340
        }
      },
      "source": [
        "# load and evaluate a saved model\n",
        "from numpy import loadtxt\n",
        "from keras.models import load_model\n",
        "\n",
        "# load model\n",
        "model = load_model('model.h5')\n",
        "# summarize model.\n",
        "model.summary()\n",
        "# load dataset\n",
        "_,_,test_images, test_labels  = load_data()\n",
        "\n",
        "# evaluate the model\n",
        "score = model.evaluate(test_images, test_labels, verbose=0)\n",
        "print(\"%s: %.2f%%\" % (model.metrics_names[1], score[1]*100))"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model_12\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_12 (InputLayer)        (None, 28, 28, 1)         0         \n",
            "_________________________________________________________________\n",
            "flatten_12 (Flatten)         (None, 784)               0         \n",
            "_________________________________________________________________\n",
            "dense_28 (Dense)             (None, 128)               100480    \n",
            "_________________________________________________________________\n",
            "dense_29 (Dense)             (None, 128)               16512     \n",
            "_________________________________________________________________\n",
            "dense_30 (Dense)             (None, 10)                1290      \n",
            "=================================================================\n",
            "Total params: 118,282\n",
            "Trainable params: 118,282\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "accuracy: 92.78%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z9X1lCeDUwEN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# make a prediction for a new image.\n",
        "from keras.preprocessing.image import load_img\n",
        "from keras.preprocessing.image import img_to_array\n",
        "from keras.models import load_model\n",
        "\n",
        "# load and prepare the image\n",
        "def load_image(filename):\n",
        "\t# load the image\n",
        "\timg = load_img(filename, grayscale=True, target_size=(28, 28))\n",
        "\t# convert to array\n",
        "\timg = img_to_array(img)\n",
        "\t# reshape into a single sample with 1 channel\n",
        "\timg = img.reshape(1, 28, 28, 1)\n",
        "\t# prepare pixel data\n",
        "\timg = img.astype('float32')\n",
        "\timg = img / 255.0\n",
        "\treturn img\n",
        "\n",
        "# load an image and predict the class\n",
        "def run_example():\n",
        "\t# load the image\n",
        "\timg = load_image('sample_image.png')\n",
        "\t# load model\n",
        "\tmodel = load_model('model.h5')\n",
        "\t# predict the class\n",
        "\tresult = model.predict_classes(img)\n",
        "\tprint(result[0])\n",
        "\n",
        "# entry point, run the example\n",
        "#run_example()"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}