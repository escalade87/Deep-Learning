{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Deep Learning Mid Term Exam #7 - Xavier and RMSProp.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "D468vNjsO308",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "93d5f163-4233-4410-a4fa-59044cfdabe9"
      },
      "source": [
        "import numpy as np\n",
        "from tensorflow import keras\n",
        "import tensorflow as tf\n",
        "import matplotlib.pyplot as plt\n",
        "import scipy.io as sio\n",
        "from keras.utils import np_utils\n",
        "from keras.models import Model\n",
        "from keras.layers import Input, Dense, Flatten\n",
        "import keras.optimizers\n",
        "from keras import regularizers\n",
        "\n",
        "import time  # To time each epoch"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lK_qEiqNO633",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def load_data(DATA_NAME = 'notMNIST_small.mat'):\n",
        "\n",
        "    rows, cols = 28, 28\n",
        "    nb_classes = 10\n",
        "\n",
        "    mat = sio.loadmat(DATA_NAME)\n",
        "\n",
        "    X = mat['images']\n",
        "    Y = mat['labels']\n",
        "\n",
        "    # Move last column to front\n",
        "    X = np.rollaxis(X, 2)\n",
        "\n",
        "    # Reshape and format input\n",
        "    X = X.reshape(X.shape[0], rows, cols, 1)\n",
        "    X = X.astype('float32')\n",
        "    X -= np.mean(X,axis=0)\n",
        "    X /= 255.0\n",
        "\n",
        "    # Hot encoding\n",
        "    Y = Y.astype(int)\n",
        "    Y = np_utils.to_categorical(Y, nb_classes)\n",
        "\n",
        "    # Divide into test and train sets\n",
        "    perm = np.random.permutation(X.shape[0])\n",
        "\n",
        "    train_size = 13000\n",
        "\n",
        "    X_train = X[perm[:train_size]]\n",
        "    X_test = X[perm[train_size:]]\n",
        "\n",
        "    Y_train = Y[perm[:train_size]]\n",
        "    Y_test = Y[perm[train_size:]]\n",
        "\n",
        "    return (X_train, Y_train, X_test, Y_test)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wGyyIfJNukkY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_images, train_labels , test_images, test_labels  = load_data()\n",
        "\n",
        "batch_size = 128\n",
        "nb_epoch = 20"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VP_KUWk1BjSm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.backend import sigmoid\n",
        "def swish(x, beta = 1):\n",
        "    return (x * sigmoid(beta * x))\n",
        "from keras.utils.generic_utils import get_custom_objects\n",
        "from keras.layers import Activation\n",
        "get_custom_objects().update({'swish': Activation(swish)})"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tWA-I955wigw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_model(activation='relu', initializer='glorot_uniform', hidden_size=128,regularizers=None):\n",
        "\n",
        "    # Model parameters\n",
        "    rows, cols = 28, 28\n",
        "    input_shape = (rows, cols, 1)\n",
        "\n",
        "    nb_classes = 10\n",
        "    \n",
        "    inp = Input(shape=input_shape)\n",
        "    flat = Flatten()(inp)\n",
        "    hidden_1 = Dense(hidden_size, activation=activation, kernel_initializer=initializer, \n",
        "                kernel_regularizer=regularizers)(flat)\n",
        "    out = Dense(nb_classes, activation='softmax')(hidden_1)\n",
        "\n",
        "    model = Model(inputs=inp, outputs=out)\n",
        "\n",
        "    print(model.summary())\n",
        "\n",
        "    return model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xPOcn8ZRtDeR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_model2(activation='relu', initializer='glorot_uniform', hidden_size=128,regularizers=None):\n",
        "\n",
        "    # Model parameters\n",
        "    rows, cols = 28, 28\n",
        "    input_shape = (rows, cols, 1)\n",
        "\n",
        "    nb_classes = 10\n",
        "    \n",
        "    inp = Input(shape=input_shape)\n",
        "    flat = Flatten()(inp)\n",
        "    hidden_1 = Dense(hidden_size, activation=activation, kernel_initializer=initializer,\n",
        "                kernel_regularizer=regularizers)(flat)\n",
        "    hidden_2 = Dense(hidden_size, activation=activation, kernel_initializer=initializer,\n",
        "                kernel_regularizer=regularizers)(hidden_1)\n",
        "    out = Dense(nb_classes, activation='softmax')(hidden_2)\n",
        "\n",
        "    model = Model(inputs=inp, outputs=out)\n",
        "\n",
        "    print(model.summary())\n",
        "\n",
        "    return model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q_VJDC2Ste7J",
        "colab_type": "text"
      },
      "source": [
        "With Xavier Initialization, One hidden layer with 32 input node, ReLU, RMSProp, without regularizer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fMrMvX5KWy01",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "5ea05846-095a-4a94-a23b-5a36a5bb2f0a"
      },
      "source": [
        "model = get_model(hidden_size=32)\n",
        "\n",
        "model.compile(loss='categorical_crossentropy', optimizer='rmsprop',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "model.fit(train_images, train_labels, batch_size=batch_size, epochs=nb_epoch,\n",
        "          verbose=1, validation_data=(test_images, test_labels))\n",
        "\n",
        "score = model.evaluate(test_images, test_labels, verbose=1)\n",
        "\n",
        "print(\"Accuracy:\", score[1])\t  "
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model_1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_1 (InputLayer)         (None, 28, 28, 1)         0         \n",
            "_________________________________________________________________\n",
            "flatten_1 (Flatten)          (None, 784)               0         \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 32)                25120     \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 10)                330       \n",
            "=================================================================\n",
            "Total params: 25,450\n",
            "Trainable params: 25,450\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n",
            "Train on 13000 samples, validate on 5724 samples\n",
            "Epoch 1/20\n",
            "13000/13000 [==============================] - 0s 31us/step - loss: 0.7066 - accuracy: 0.8190 - val_loss: 0.4527 - val_accuracy: 0.8768\n",
            "Epoch 2/20\n",
            "13000/13000 [==============================] - 0s 24us/step - loss: 0.3852 - accuracy: 0.8912 - val_loss: 0.3929 - val_accuracy: 0.8905\n",
            "Epoch 3/20\n",
            "13000/13000 [==============================] - 0s 23us/step - loss: 0.3283 - accuracy: 0.9042 - val_loss: 0.3710 - val_accuracy: 0.8968\n",
            "Epoch 4/20\n",
            "13000/13000 [==============================] - 0s 22us/step - loss: 0.2960 - accuracy: 0.9136 - val_loss: 0.3585 - val_accuracy: 0.8988\n",
            "Epoch 5/20\n",
            "13000/13000 [==============================] - 0s 22us/step - loss: 0.2728 - accuracy: 0.9202 - val_loss: 0.3524 - val_accuracy: 0.9037\n",
            "Epoch 6/20\n",
            "13000/13000 [==============================] - 0s 24us/step - loss: 0.2521 - accuracy: 0.9272 - val_loss: 0.3494 - val_accuracy: 0.9029\n",
            "Epoch 7/20\n",
            "13000/13000 [==============================] - 0s 23us/step - loss: 0.2346 - accuracy: 0.9315 - val_loss: 0.3476 - val_accuracy: 0.9022\n",
            "Epoch 8/20\n",
            "13000/13000 [==============================] - 0s 24us/step - loss: 0.2202 - accuracy: 0.9368 - val_loss: 0.3462 - val_accuracy: 0.9058\n",
            "Epoch 9/20\n",
            "13000/13000 [==============================] - 0s 24us/step - loss: 0.2082 - accuracy: 0.9396 - val_loss: 0.3509 - val_accuracy: 0.9053\n",
            "Epoch 10/20\n",
            "13000/13000 [==============================] - 0s 24us/step - loss: 0.1965 - accuracy: 0.9424 - val_loss: 0.3471 - val_accuracy: 0.9065\n",
            "Epoch 11/20\n",
            "13000/13000 [==============================] - 0s 23us/step - loss: 0.1865 - accuracy: 0.9458 - val_loss: 0.3468 - val_accuracy: 0.9067\n",
            "Epoch 12/20\n",
            "13000/13000 [==============================] - 0s 24us/step - loss: 0.1755 - accuracy: 0.9508 - val_loss: 0.3534 - val_accuracy: 0.9029\n",
            "Epoch 13/20\n",
            "13000/13000 [==============================] - 0s 23us/step - loss: 0.1670 - accuracy: 0.9528 - val_loss: 0.3544 - val_accuracy: 0.9058\n",
            "Epoch 14/20\n",
            "13000/13000 [==============================] - 0s 22us/step - loss: 0.1581 - accuracy: 0.9563 - val_loss: 0.3593 - val_accuracy: 0.9043\n",
            "Epoch 15/20\n",
            "13000/13000 [==============================] - 0s 22us/step - loss: 0.1507 - accuracy: 0.9593 - val_loss: 0.3605 - val_accuracy: 0.9071\n",
            "Epoch 16/20\n",
            "13000/13000 [==============================] - 0s 22us/step - loss: 0.1421 - accuracy: 0.9592 - val_loss: 0.3642 - val_accuracy: 0.9062\n",
            "Epoch 17/20\n",
            "13000/13000 [==============================] - 0s 23us/step - loss: 0.1357 - accuracy: 0.9618 - val_loss: 0.3685 - val_accuracy: 0.9051\n",
            "Epoch 18/20\n",
            "13000/13000 [==============================] - 0s 23us/step - loss: 0.1279 - accuracy: 0.9645 - val_loss: 0.3758 - val_accuracy: 0.9062\n",
            "Epoch 19/20\n",
            "13000/13000 [==============================] - 0s 23us/step - loss: 0.1220 - accuracy: 0.9656 - val_loss: 0.3756 - val_accuracy: 0.9062\n",
            "Epoch 20/20\n",
            "13000/13000 [==============================] - 0s 23us/step - loss: 0.1156 - accuracy: 0.9702 - val_loss: 0.3850 - val_accuracy: 0.9058\n",
            "5724/5724 [==============================] - 0s 22us/step\n",
            "Accuracy: 0.9058350920677185\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v3U6ONn94LXA",
        "colab_type": "text"
      },
      "source": [
        "With Xavier Initialization, One hidden layer with 32 input node, ReLU, RMSProp, with L1 regularizer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "de7jHrz83AX4",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "36bb15bf-ecfc-421d-c3f6-428e48e95017"
      },
      "source": [
        "model = get_model(hidden_size=32,regularizers=regularizers.l1(0.01))\n",
        "\n",
        "model.compile(loss='categorical_crossentropy', optimizer='rmsprop',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "model.fit(train_images, train_labels, batch_size=batch_size, epochs=nb_epoch,\n",
        "          verbose=1, validation_data=(test_images, test_labels))\n",
        "\n",
        "score = model.evaluate(test_images, test_labels, verbose=1)\n",
        "\n",
        "print(\"Accuracy:\", score[1])"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model_2\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_2 (InputLayer)         (None, 28, 28, 1)         0         \n",
            "_________________________________________________________________\n",
            "flatten_2 (Flatten)          (None, 784)               0         \n",
            "_________________________________________________________________\n",
            "dense_3 (Dense)              (None, 32)                25120     \n",
            "_________________________________________________________________\n",
            "dense_4 (Dense)              (None, 10)                330       \n",
            "=================================================================\n",
            "Total params: 25,450\n",
            "Trainable params: 25,450\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n",
            "Train on 13000 samples, validate on 5724 samples\n",
            "Epoch 1/20\n",
            "13000/13000 [==============================] - 0s 31us/step - loss: 4.7781 - accuracy: 0.7540 - val_loss: 1.8934 - val_accuracy: 0.8302\n",
            "Epoch 2/20\n",
            "13000/13000 [==============================] - 0s 22us/step - loss: 1.6893 - accuracy: 0.8371 - val_loss: 1.5752 - val_accuracy: 0.8422\n",
            "Epoch 3/20\n",
            "13000/13000 [==============================] - 0s 22us/step - loss: 1.4531 - accuracy: 0.8439 - val_loss: 1.4158 - val_accuracy: 0.8449\n",
            "Epoch 4/20\n",
            "13000/13000 [==============================] - 0s 22us/step - loss: 1.3181 - accuracy: 0.8472 - val_loss: 1.3059 - val_accuracy: 0.8440\n",
            "Epoch 5/20\n",
            "13000/13000 [==============================] - 0s 22us/step - loss: 1.2329 - accuracy: 0.8499 - val_loss: 1.2869 - val_accuracy: 0.8244\n",
            "Epoch 6/20\n",
            "13000/13000 [==============================] - 0s 21us/step - loss: 1.1797 - accuracy: 0.8501 - val_loss: 1.2193 - val_accuracy: 0.8450\n",
            "Epoch 7/20\n",
            "13000/13000 [==============================] - 0s 22us/step - loss: 1.1415 - accuracy: 0.8508 - val_loss: 1.2341 - val_accuracy: 0.8353\n",
            "Epoch 8/20\n",
            "13000/13000 [==============================] - 0s 24us/step - loss: 1.1077 - accuracy: 0.8542 - val_loss: 1.1253 - val_accuracy: 0.8573\n",
            "Epoch 9/20\n",
            "13000/13000 [==============================] - 0s 23us/step - loss: 1.0894 - accuracy: 0.8532 - val_loss: 1.1181 - val_accuracy: 0.8536\n",
            "Epoch 10/20\n",
            "13000/13000 [==============================] - 0s 23us/step - loss: 1.0657 - accuracy: 0.8572 - val_loss: 1.1372 - val_accuracy: 0.8346\n",
            "Epoch 11/20\n",
            "13000/13000 [==============================] - 0s 23us/step - loss: 1.0505 - accuracy: 0.8581 - val_loss: 1.0573 - val_accuracy: 0.8508\n",
            "Epoch 12/20\n",
            "13000/13000 [==============================] - 0s 22us/step - loss: 1.0391 - accuracy: 0.8530 - val_loss: 1.0719 - val_accuracy: 0.8552\n",
            "Epoch 13/20\n",
            "13000/13000 [==============================] - 0s 21us/step - loss: 1.0270 - accuracy: 0.8566 - val_loss: 1.0952 - val_accuracy: 0.8367\n",
            "Epoch 14/20\n",
            "13000/13000 [==============================] - 0s 23us/step - loss: 1.0162 - accuracy: 0.8562 - val_loss: 1.1321 - val_accuracy: 0.8202\n",
            "Epoch 15/20\n",
            "13000/13000 [==============================] - 0s 23us/step - loss: 1.0079 - accuracy: 0.8565 - val_loss: 1.0575 - val_accuracy: 0.8517\n",
            "Epoch 16/20\n",
            "13000/13000 [==============================] - 0s 23us/step - loss: 0.9989 - accuracy: 0.8585 - val_loss: 1.1130 - val_accuracy: 0.8335\n",
            "Epoch 17/20\n",
            "13000/13000 [==============================] - 0s 23us/step - loss: 0.9958 - accuracy: 0.8575 - val_loss: 1.0042 - val_accuracy: 0.8573\n",
            "Epoch 18/20\n",
            "13000/13000 [==============================] - 0s 23us/step - loss: 0.9830 - accuracy: 0.8599 - val_loss: 1.0398 - val_accuracy: 0.8433\n",
            "Epoch 19/20\n",
            "13000/13000 [==============================] - 0s 22us/step - loss: 0.9773 - accuracy: 0.8595 - val_loss: 1.0333 - val_accuracy: 0.8562\n",
            "Epoch 20/20\n",
            "13000/13000 [==============================] - 0s 23us/step - loss: 0.9717 - accuracy: 0.8613 - val_loss: 1.0494 - val_accuracy: 0.8417\n",
            "5724/5724 [==============================] - 0s 22us/step\n",
            "Accuracy: 0.8417190909385681\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IIXS1TtK3KAv",
        "colab_type": "text"
      },
      "source": [
        "With Xavier Initialization, One hidden layer with 32 input node, ReLU, RMSProp, with L2 regularizer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZVA_LNgA3_I3",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "50104d2a-d52a-482e-f570-f18a56529821"
      },
      "source": [
        "model = get_model(hidden_size=32,regularizers=regularizers.l2(0.01))\n",
        "\n",
        "model.compile(loss='categorical_crossentropy', optimizer='rmsprop',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "model.fit(train_images, train_labels, batch_size=batch_size, epochs=nb_epoch,\n",
        "          verbose=1, validation_data=(test_images, test_labels))\n",
        "\n",
        "score = model.evaluate(test_images, test_labels, verbose=1)\n",
        "\n",
        "print(\"Accuracy:\", score[1])"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model_3\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_3 (InputLayer)         (None, 28, 28, 1)         0         \n",
            "_________________________________________________________________\n",
            "flatten_3 (Flatten)          (None, 784)               0         \n",
            "_________________________________________________________________\n",
            "dense_5 (Dense)              (None, 32)                25120     \n",
            "_________________________________________________________________\n",
            "dense_6 (Dense)              (None, 10)                330       \n",
            "=================================================================\n",
            "Total params: 25,450\n",
            "Trainable params: 25,450\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n",
            "Train on 13000 samples, validate on 5724 samples\n",
            "Epoch 1/20\n",
            "13000/13000 [==============================] - 0s 29us/step - loss: 1.2499 - accuracy: 0.8045 - val_loss: 0.8209 - val_accuracy: 0.8735\n",
            "Epoch 2/20\n",
            "13000/13000 [==============================] - 0s 23us/step - loss: 0.6773 - accuracy: 0.8850 - val_loss: 0.6113 - val_accuracy: 0.8898\n",
            "Epoch 3/20\n",
            "13000/13000 [==============================] - 0s 22us/step - loss: 0.5406 - accuracy: 0.8946 - val_loss: 0.5367 - val_accuracy: 0.8877\n",
            "Epoch 4/20\n",
            "13000/13000 [==============================] - 0s 23us/step - loss: 0.4852 - accuracy: 0.8981 - val_loss: 0.5055 - val_accuracy: 0.8915\n",
            "Epoch 5/20\n",
            "13000/13000 [==============================] - 0s 23us/step - loss: 0.4555 - accuracy: 0.9033 - val_loss: 0.4871 - val_accuracy: 0.8927\n",
            "Epoch 6/20\n",
            "13000/13000 [==============================] - 0s 23us/step - loss: 0.4372 - accuracy: 0.9056 - val_loss: 0.4785 - val_accuracy: 0.8943\n",
            "Epoch 7/20\n",
            "13000/13000 [==============================] - 0s 23us/step - loss: 0.4231 - accuracy: 0.9077 - val_loss: 0.4704 - val_accuracy: 0.8943\n",
            "Epoch 8/20\n",
            "13000/13000 [==============================] - 0s 23us/step - loss: 0.4122 - accuracy: 0.9092 - val_loss: 0.4654 - val_accuracy: 0.8933\n",
            "Epoch 9/20\n",
            "13000/13000 [==============================] - 0s 23us/step - loss: 0.4024 - accuracy: 0.9122 - val_loss: 0.4475 - val_accuracy: 0.9018\n",
            "Epoch 10/20\n",
            "13000/13000 [==============================] - 0s 23us/step - loss: 0.3947 - accuracy: 0.9115 - val_loss: 0.4489 - val_accuracy: 0.9020\n",
            "Epoch 11/20\n",
            "13000/13000 [==============================] - 0s 22us/step - loss: 0.3886 - accuracy: 0.9151 - val_loss: 0.4603 - val_accuracy: 0.8929\n",
            "Epoch 12/20\n",
            "13000/13000 [==============================] - 0s 23us/step - loss: 0.3810 - accuracy: 0.9156 - val_loss: 0.4585 - val_accuracy: 0.8987\n",
            "Epoch 13/20\n",
            "13000/13000 [==============================] - 0s 23us/step - loss: 0.3760 - accuracy: 0.9178 - val_loss: 0.4433 - val_accuracy: 0.9009\n",
            "Epoch 14/20\n",
            "13000/13000 [==============================] - 0s 22us/step - loss: 0.3707 - accuracy: 0.9178 - val_loss: 0.4436 - val_accuracy: 0.8997\n",
            "Epoch 15/20\n",
            "13000/13000 [==============================] - 0s 21us/step - loss: 0.3673 - accuracy: 0.9179 - val_loss: 0.4318 - val_accuracy: 0.9037\n",
            "Epoch 16/20\n",
            "13000/13000 [==============================] - 0s 22us/step - loss: 0.3627 - accuracy: 0.9182 - val_loss: 0.4546 - val_accuracy: 0.8961\n",
            "Epoch 17/20\n",
            "13000/13000 [==============================] - 0s 22us/step - loss: 0.3598 - accuracy: 0.9192 - val_loss: 0.4417 - val_accuracy: 0.8973\n",
            "Epoch 18/20\n",
            "13000/13000 [==============================] - 0s 22us/step - loss: 0.3559 - accuracy: 0.9204 - val_loss: 0.4465 - val_accuracy: 0.8968\n",
            "Epoch 19/20\n",
            "13000/13000 [==============================] - 0s 21us/step - loss: 0.3537 - accuracy: 0.9208 - val_loss: 0.4361 - val_accuracy: 0.9030\n",
            "Epoch 20/20\n",
            "13000/13000 [==============================] - 0s 22us/step - loss: 0.3494 - accuracy: 0.9248 - val_loss: 0.4291 - val_accuracy: 0.9020\n",
            "5724/5724 [==============================] - 0s 22us/step\n",
            "Accuracy: 0.901991605758667\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "dw2mZ3PL4Vpq"
      },
      "source": [
        "With Xavier Initialization, Two hidden layer with each layer contains 128 input node, ReLU, RMSProp, without regularizer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "bcf88018-dda6-4894-8773-7ba12eab45cc",
        "id": "M1uISYFs4Vpr",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "model = get_model2(hidden_size=128)\n",
        "\n",
        "model.compile(loss='categorical_crossentropy', optimizer='rmsprop',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "model.fit(train_images, train_labels, batch_size=batch_size, epochs=nb_epoch,\n",
        "          verbose=1, validation_data=(test_images, test_labels))\n",
        "\n",
        "score = model.evaluate(test_images, test_labels, verbose=1)\n",
        "\n",
        "print(\"Accuracy:\", score[1])\t  "
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model_4\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_4 (InputLayer)         (None, 28, 28, 1)         0         \n",
            "_________________________________________________________________\n",
            "flatten_4 (Flatten)          (None, 784)               0         \n",
            "_________________________________________________________________\n",
            "dense_7 (Dense)              (None, 128)               100480    \n",
            "_________________________________________________________________\n",
            "dense_8 (Dense)              (None, 128)               16512     \n",
            "_________________________________________________________________\n",
            "dense_9 (Dense)              (None, 10)                1290      \n",
            "=================================================================\n",
            "Total params: 118,282\n",
            "Trainable params: 118,282\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n",
            "Train on 13000 samples, validate on 5724 samples\n",
            "Epoch 1/20\n",
            "13000/13000 [==============================] - 1s 45us/step - loss: 0.5025 - accuracy: 0.8570 - val_loss: 0.3540 - val_accuracy: 0.8974\n",
            "Epoch 2/20\n",
            "13000/13000 [==============================] - 1s 39us/step - loss: 0.2889 - accuracy: 0.9129 - val_loss: 0.3322 - val_accuracy: 0.9004\n",
            "Epoch 3/20\n",
            "13000/13000 [==============================] - 1s 42us/step - loss: 0.2373 - accuracy: 0.9291 - val_loss: 0.3362 - val_accuracy: 0.8999\n",
            "Epoch 4/20\n",
            "13000/13000 [==============================] - 1s 40us/step - loss: 0.1958 - accuracy: 0.9392 - val_loss: 0.3189 - val_accuracy: 0.9119\n",
            "Epoch 5/20\n",
            "13000/13000 [==============================] - 1s 40us/step - loss: 0.1611 - accuracy: 0.9497 - val_loss: 0.3323 - val_accuracy: 0.9095\n",
            "Epoch 6/20\n",
            "13000/13000 [==============================] - 1s 41us/step - loss: 0.1338 - accuracy: 0.9582 - val_loss: 0.3380 - val_accuracy: 0.9114\n",
            "Epoch 7/20\n",
            "13000/13000 [==============================] - 1s 39us/step - loss: 0.1100 - accuracy: 0.9664 - val_loss: 0.3411 - val_accuracy: 0.9140\n",
            "Epoch 8/20\n",
            "13000/13000 [==============================] - 1s 41us/step - loss: 0.0890 - accuracy: 0.9739 - val_loss: 0.3447 - val_accuracy: 0.9153\n",
            "Epoch 9/20\n",
            "13000/13000 [==============================] - 1s 40us/step - loss: 0.0741 - accuracy: 0.9774 - val_loss: 0.3944 - val_accuracy: 0.9116\n",
            "Epoch 10/20\n",
            "13000/13000 [==============================] - 1s 41us/step - loss: 0.0613 - accuracy: 0.9815 - val_loss: 0.4248 - val_accuracy: 0.9055\n",
            "Epoch 11/20\n",
            "13000/13000 [==============================] - 1s 42us/step - loss: 0.0510 - accuracy: 0.9852 - val_loss: 0.4033 - val_accuracy: 0.9170\n",
            "Epoch 12/20\n",
            "13000/13000 [==============================] - 1s 40us/step - loss: 0.0447 - accuracy: 0.9866 - val_loss: 0.4225 - val_accuracy: 0.9147\n",
            "Epoch 13/20\n",
            "13000/13000 [==============================] - 1s 39us/step - loss: 0.0371 - accuracy: 0.9888 - val_loss: 0.4542 - val_accuracy: 0.9126\n",
            "Epoch 14/20\n",
            "13000/13000 [==============================] - 1s 39us/step - loss: 0.0355 - accuracy: 0.9896 - val_loss: 0.4845 - val_accuracy: 0.9074\n",
            "Epoch 15/20\n",
            "13000/13000 [==============================] - 1s 40us/step - loss: 0.0292 - accuracy: 0.9928 - val_loss: 0.4606 - val_accuracy: 0.9158\n",
            "Epoch 16/20\n",
            "13000/13000 [==============================] - 1s 41us/step - loss: 0.0255 - accuracy: 0.9924 - val_loss: 0.5392 - val_accuracy: 0.9111\n",
            "Epoch 17/20\n",
            "13000/13000 [==============================] - 1s 42us/step - loss: 0.0270 - accuracy: 0.9921 - val_loss: 0.5062 - val_accuracy: 0.9188\n",
            "Epoch 18/20\n",
            "13000/13000 [==============================] - 1s 39us/step - loss: 0.0222 - accuracy: 0.9942 - val_loss: 0.5629 - val_accuracy: 0.9126\n",
            "Epoch 19/20\n",
            "13000/13000 [==============================] - 1s 40us/step - loss: 0.0216 - accuracy: 0.9938 - val_loss: 0.5719 - val_accuracy: 0.9116\n",
            "Epoch 20/20\n",
            "13000/13000 [==============================] - 1s 39us/step - loss: 0.0208 - accuracy: 0.9938 - val_loss: 0.5603 - val_accuracy: 0.9158\n",
            "5724/5724 [==============================] - 0s 29us/step\n",
            "Accuracy: 0.9157931804656982\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "Or2DziC74Vpv"
      },
      "source": [
        "With Xavier Initialization, Two hidden layer with each layer contains 128 input node, ReLU, RMSProp, with L1 regularizer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "FVp1SNIJ4Vpv",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "332a3578-cde1-4ff7-d4ac-a685c84f7766"
      },
      "source": [
        "model = get_model2(hidden_size=128,regularizers=regularizers.l1(0.01))\n",
        "\n",
        "model.compile(loss='categorical_crossentropy', optimizer='rmsprop',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "model.fit(train_images, train_labels, batch_size=batch_size, epochs=nb_epoch,\n",
        "          verbose=1, validation_data=(test_images, test_labels))\n",
        "\n",
        "score = model.evaluate(test_images, test_labels, verbose=1)\n",
        "\n",
        "print(\"Accuracy:\", score[1])"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model_5\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_5 (InputLayer)         (None, 28, 28, 1)         0         \n",
            "_________________________________________________________________\n",
            "flatten_5 (Flatten)          (None, 784)               0         \n",
            "_________________________________________________________________\n",
            "dense_10 (Dense)             (None, 128)               100480    \n",
            "_________________________________________________________________\n",
            "dense_11 (Dense)             (None, 128)               16512     \n",
            "_________________________________________________________________\n",
            "dense_12 (Dense)             (None, 10)                1290      \n",
            "=================================================================\n",
            "Total params: 118,282\n",
            "Trainable params: 118,282\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n",
            "Train on 13000 samples, validate on 5724 samples\n",
            "Epoch 1/20\n",
            "13000/13000 [==============================] - 1s 53us/step - loss: 16.4017 - accuracy: 0.5154 - val_loss: 3.6536 - val_accuracy: 0.5393\n",
            "Epoch 2/20\n",
            "13000/13000 [==============================] - 1s 46us/step - loss: 2.6077 - accuracy: 0.5262 - val_loss: 2.3235 - val_accuracy: 0.5564\n",
            "Epoch 3/20\n",
            "13000/13000 [==============================] - 1s 42us/step - loss: 2.2076 - accuracy: 0.6255 - val_loss: 2.1479 - val_accuracy: 0.6815\n",
            "Epoch 4/20\n",
            "13000/13000 [==============================] - 1s 43us/step - loss: 2.0311 - accuracy: 0.7248 - val_loss: 1.9782 - val_accuracy: 0.7586\n",
            "Epoch 5/20\n",
            "13000/13000 [==============================] - 1s 42us/step - loss: 1.8987 - accuracy: 0.7886 - val_loss: 1.8824 - val_accuracy: 0.7928\n",
            "Epoch 6/20\n",
            "13000/13000 [==============================] - 1s 47us/step - loss: 1.8063 - accuracy: 0.8085 - val_loss: 1.8038 - val_accuracy: 0.8071\n",
            "Epoch 7/20\n",
            "13000/13000 [==============================] - 1s 46us/step - loss: 1.7440 - accuracy: 0.8189 - val_loss: 1.7360 - val_accuracy: 0.8235\n",
            "Epoch 8/20\n",
            "13000/13000 [==============================] - 1s 46us/step - loss: 1.6968 - accuracy: 0.8255 - val_loss: 1.7127 - val_accuracy: 0.8276\n",
            "Epoch 9/20\n",
            "13000/13000 [==============================] - 1s 45us/step - loss: 1.6574 - accuracy: 0.8393 - val_loss: 1.6577 - val_accuracy: 0.8442\n",
            "Epoch 10/20\n",
            "13000/13000 [==============================] - 1s 46us/step - loss: 1.6298 - accuracy: 0.8429 - val_loss: 1.6306 - val_accuracy: 0.8508\n",
            "Epoch 11/20\n",
            "13000/13000 [==============================] - 1s 45us/step - loss: 1.6045 - accuracy: 0.8459 - val_loss: 1.6148 - val_accuracy: 0.8475\n",
            "Epoch 12/20\n",
            "13000/13000 [==============================] - 1s 46us/step - loss: 1.5849 - accuracy: 0.8514 - val_loss: 1.6009 - val_accuracy: 0.8555\n",
            "Epoch 13/20\n",
            "13000/13000 [==============================] - 1s 45us/step - loss: 1.5688 - accuracy: 0.8532 - val_loss: 1.6021 - val_accuracy: 0.8463\n",
            "Epoch 14/20\n",
            "13000/13000 [==============================] - 1s 45us/step - loss: 1.5570 - accuracy: 0.8520 - val_loss: 1.5725 - val_accuracy: 0.8545\n",
            "Epoch 15/20\n",
            "13000/13000 [==============================] - 1s 46us/step - loss: 1.5446 - accuracy: 0.8552 - val_loss: 1.6161 - val_accuracy: 0.8300\n",
            "Epoch 16/20\n",
            "13000/13000 [==============================] - 1s 44us/step - loss: 1.5335 - accuracy: 0.8582 - val_loss: 1.5488 - val_accuracy: 0.8620\n",
            "Epoch 17/20\n",
            "13000/13000 [==============================] - 1s 45us/step - loss: 1.5265 - accuracy: 0.8565 - val_loss: 1.5443 - val_accuracy: 0.8578\n",
            "Epoch 18/20\n",
            "13000/13000 [==============================] - 1s 43us/step - loss: 1.5166 - accuracy: 0.8572 - val_loss: 1.5630 - val_accuracy: 0.8480\n",
            "Epoch 19/20\n",
            "13000/13000 [==============================] - 1s 42us/step - loss: 1.5104 - accuracy: 0.8589 - val_loss: 1.5596 - val_accuracy: 0.8501\n",
            "Epoch 20/20\n",
            "13000/13000 [==============================] - 1s 43us/step - loss: 1.5050 - accuracy: 0.8568 - val_loss: 1.5692 - val_accuracy: 0.8471\n",
            "5724/5724 [==============================] - 0s 31us/step\n",
            "Accuracy: 0.8471348881721497\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "8olj8yk84Vpx"
      },
      "source": [
        "With Xavier Initialization, Two hidden layer with each layer contains 128 input node, ReLU, RMSProp, with L2\n",
        "regularizer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "EB2LNNNm4Vpy",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "3958cd50-6f2e-4325-f3bd-8aa7ceb3662c"
      },
      "source": [
        "model = get_model2(hidden_size=128,regularizers=regularizers.l2(0.01))\n",
        "\n",
        "model.compile(loss='categorical_crossentropy', optimizer='rmsprop',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "model.fit(train_images, train_labels, batch_size=batch_size, epochs=nb_epoch,\n",
        "          verbose=1, validation_data=(test_images, test_labels))\n",
        "\n",
        "score = model.evaluate(test_images, test_labels, verbose=1)\n",
        "\n",
        "print(\"Accuracy:\", score[1])"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model_6\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_6 (InputLayer)         (None, 28, 28, 1)         0         \n",
            "_________________________________________________________________\n",
            "flatten_6 (Flatten)          (None, 784)               0         \n",
            "_________________________________________________________________\n",
            "dense_13 (Dense)             (None, 128)               100480    \n",
            "_________________________________________________________________\n",
            "dense_14 (Dense)             (None, 128)               16512     \n",
            "_________________________________________________________________\n",
            "dense_15 (Dense)             (None, 10)                1290      \n",
            "=================================================================\n",
            "Total params: 118,282\n",
            "Trainable params: 118,282\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n",
            "Train on 13000 samples, validate on 5724 samples\n",
            "Epoch 1/20\n",
            "13000/13000 [==============================] - 1s 52us/step - loss: 2.3017 - accuracy: 0.8532 - val_loss: 1.1471 - val_accuracy: 0.8861\n",
            "Epoch 2/20\n",
            "13000/13000 [==============================] - 1s 45us/step - loss: 0.8260 - accuracy: 0.8927 - val_loss: 0.6903 - val_accuracy: 0.8880\n",
            "Epoch 3/20\n",
            "13000/13000 [==============================] - 1s 44us/step - loss: 0.5975 - accuracy: 0.8981 - val_loss: 0.5878 - val_accuracy: 0.8934\n",
            "Epoch 4/20\n",
            "13000/13000 [==============================] - 1s 41us/step - loss: 0.5423 - accuracy: 0.9015 - val_loss: 0.5571 - val_accuracy: 0.8948\n",
            "Epoch 5/20\n",
            "13000/13000 [==============================] - 1s 41us/step - loss: 0.5158 - accuracy: 0.9039 - val_loss: 0.5629 - val_accuracy: 0.8962\n",
            "Epoch 6/20\n",
            "13000/13000 [==============================] - 1s 41us/step - loss: 0.4979 - accuracy: 0.9038 - val_loss: 0.5480 - val_accuracy: 0.8891\n",
            "Epoch 7/20\n",
            "13000/13000 [==============================] - 1s 42us/step - loss: 0.4828 - accuracy: 0.9058 - val_loss: 0.5255 - val_accuracy: 0.8948\n",
            "Epoch 8/20\n",
            "13000/13000 [==============================] - 1s 43us/step - loss: 0.4710 - accuracy: 0.9077 - val_loss: 0.5240 - val_accuracy: 0.8943\n",
            "Epoch 9/20\n",
            "13000/13000 [==============================] - 1s 45us/step - loss: 0.4572 - accuracy: 0.9085 - val_loss: 0.5018 - val_accuracy: 0.9004\n",
            "Epoch 10/20\n",
            "13000/13000 [==============================] - 1s 44us/step - loss: 0.4497 - accuracy: 0.9124 - val_loss: 0.5140 - val_accuracy: 0.8885\n",
            "Epoch 11/20\n",
            "13000/13000 [==============================] - 1s 41us/step - loss: 0.4393 - accuracy: 0.9130 - val_loss: 0.4932 - val_accuracy: 0.8983\n",
            "Epoch 12/20\n",
            "13000/13000 [==============================] - 1s 41us/step - loss: 0.4312 - accuracy: 0.9157 - val_loss: 0.4830 - val_accuracy: 0.9032\n",
            "Epoch 13/20\n",
            "13000/13000 [==============================] - 1s 41us/step - loss: 0.4255 - accuracy: 0.9182 - val_loss: 0.4897 - val_accuracy: 0.8964\n",
            "Epoch 14/20\n",
            "13000/13000 [==============================] - 1s 42us/step - loss: 0.4195 - accuracy: 0.9163 - val_loss: 0.4797 - val_accuracy: 0.9039\n",
            "Epoch 15/20\n",
            "13000/13000 [==============================] - 1s 42us/step - loss: 0.4113 - accuracy: 0.9203 - val_loss: 0.4778 - val_accuracy: 0.9004\n",
            "Epoch 16/20\n",
            "13000/13000 [==============================] - 1s 40us/step - loss: 0.4102 - accuracy: 0.9182 - val_loss: 0.5192 - val_accuracy: 0.8840\n",
            "Epoch 17/20\n",
            "13000/13000 [==============================] - 1s 41us/step - loss: 0.4028 - accuracy: 0.9197 - val_loss: 0.4624 - val_accuracy: 0.9050\n",
            "Epoch 18/20\n",
            "13000/13000 [==============================] - 1s 43us/step - loss: 0.3988 - accuracy: 0.9208 - val_loss: 0.4830 - val_accuracy: 0.9018\n",
            "Epoch 19/20\n",
            "13000/13000 [==============================] - 1s 44us/step - loss: 0.3950 - accuracy: 0.9210 - val_loss: 0.4657 - val_accuracy: 0.9044\n",
            "Epoch 20/20\n",
            "13000/13000 [==============================] - 1s 43us/step - loss: 0.3898 - accuracy: 0.9228 - val_loss: 0.4825 - val_accuracy: 0.8980\n",
            "5724/5724 [==============================] - 0s 29us/step\n",
            "Accuracy: 0.8979734182357788\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "0216p6rE56Xi"
      },
      "source": [
        "With Xavier Initialization, One hidden layer with 32 input node, Swish, RMSProp, without regularizer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "8737b7a4-79e9-4692-8d9f-d3ab13d4b471",
        "id": "yhI0_2oT56Xl",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "model = get_model(hidden_size=32,activation='swish')\n",
        "\n",
        "model.compile(loss='categorical_crossentropy', optimizer='rmsprop',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "model.fit(train_images, train_labels, batch_size=batch_size, epochs=nb_epoch,\n",
        "          verbose=1, validation_data=(test_images, test_labels))\n",
        "\n",
        "score = model.evaluate(test_images, test_labels, verbose=1)\n",
        "\n",
        "print(\"Accuracy:\", score[1])\t  "
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model_7\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_7 (InputLayer)         (None, 28, 28, 1)         0         \n",
            "_________________________________________________________________\n",
            "flatten_7 (Flatten)          (None, 784)               0         \n",
            "_________________________________________________________________\n",
            "dense_16 (Dense)             (None, 32)                25120     \n",
            "_________________________________________________________________\n",
            "dense_17 (Dense)             (None, 10)                330       \n",
            "=================================================================\n",
            "Total params: 25,450\n",
            "Trainable params: 25,450\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n",
            "Train on 13000 samples, validate on 5724 samples\n",
            "Epoch 1/20\n",
            "13000/13000 [==============================] - 0s 30us/step - loss: 0.6614 - accuracy: 0.8269 - val_loss: 0.4297 - val_accuracy: 0.8836\n",
            "Epoch 2/20\n",
            "13000/13000 [==============================] - 0s 25us/step - loss: 0.3733 - accuracy: 0.8929 - val_loss: 0.3826 - val_accuracy: 0.8955\n",
            "Epoch 3/20\n",
            "13000/13000 [==============================] - 0s 28us/step - loss: 0.3210 - accuracy: 0.9061 - val_loss: 0.3619 - val_accuracy: 0.8999\n",
            "Epoch 4/20\n",
            "13000/13000 [==============================] - 0s 29us/step - loss: 0.2901 - accuracy: 0.9152 - val_loss: 0.3456 - val_accuracy: 0.9034\n",
            "Epoch 5/20\n",
            "13000/13000 [==============================] - 0s 30us/step - loss: 0.2650 - accuracy: 0.9202 - val_loss: 0.3415 - val_accuracy: 0.9041\n",
            "Epoch 6/20\n",
            "13000/13000 [==============================] - 0s 27us/step - loss: 0.2480 - accuracy: 0.9279 - val_loss: 0.3362 - val_accuracy: 0.9069\n",
            "Epoch 7/20\n",
            "13000/13000 [==============================] - 0s 27us/step - loss: 0.2311 - accuracy: 0.9302 - val_loss: 0.3350 - val_accuracy: 0.9095\n",
            "Epoch 8/20\n",
            "13000/13000 [==============================] - 0s 28us/step - loss: 0.2178 - accuracy: 0.9375 - val_loss: 0.3331 - val_accuracy: 0.9097\n",
            "Epoch 9/20\n",
            "13000/13000 [==============================] - 0s 27us/step - loss: 0.2044 - accuracy: 0.9398 - val_loss: 0.3347 - val_accuracy: 0.9104\n",
            "Epoch 10/20\n",
            "13000/13000 [==============================] - 0s 27us/step - loss: 0.1925 - accuracy: 0.9454 - val_loss: 0.3381 - val_accuracy: 0.9107\n",
            "Epoch 11/20\n",
            "13000/13000 [==============================] - 0s 28us/step - loss: 0.1814 - accuracy: 0.9465 - val_loss: 0.3366 - val_accuracy: 0.9104\n",
            "Epoch 12/20\n",
            "13000/13000 [==============================] - 0s 26us/step - loss: 0.1720 - accuracy: 0.9495 - val_loss: 0.3414 - val_accuracy: 0.9113\n",
            "Epoch 13/20\n",
            "13000/13000 [==============================] - 0s 27us/step - loss: 0.1625 - accuracy: 0.9527 - val_loss: 0.3411 - val_accuracy: 0.9116\n",
            "Epoch 14/20\n",
            "13000/13000 [==============================] - 0s 27us/step - loss: 0.1540 - accuracy: 0.9558 - val_loss: 0.3453 - val_accuracy: 0.9097\n",
            "Epoch 15/20\n",
            "13000/13000 [==============================] - 0s 25us/step - loss: 0.1447 - accuracy: 0.9597 - val_loss: 0.3498 - val_accuracy: 0.9111\n",
            "Epoch 16/20\n",
            "13000/13000 [==============================] - 0s 25us/step - loss: 0.1376 - accuracy: 0.9600 - val_loss: 0.3538 - val_accuracy: 0.9078\n",
            "Epoch 17/20\n",
            "13000/13000 [==============================] - 0s 28us/step - loss: 0.1296 - accuracy: 0.9645 - val_loss: 0.3618 - val_accuracy: 0.9062\n",
            "Epoch 18/20\n",
            "13000/13000 [==============================] - 0s 28us/step - loss: 0.1229 - accuracy: 0.9660 - val_loss: 0.3603 - val_accuracy: 0.9081\n",
            "Epoch 19/20\n",
            "13000/13000 [==============================] - 0s 27us/step - loss: 0.1162 - accuracy: 0.9689 - val_loss: 0.3629 - val_accuracy: 0.9090\n",
            "Epoch 20/20\n",
            "13000/13000 [==============================] - 0s 26us/step - loss: 0.1099 - accuracy: 0.9712 - val_loss: 0.3698 - val_accuracy: 0.9086\n",
            "5724/5724 [==============================] - 0s 21us/step\n",
            "Accuracy: 0.9086303114891052\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "-m_pB7ak56Xp"
      },
      "source": [
        "With Xavier Initialization, One hidden layer with 32 input node, Swish, RMSProp, with L1 regularizer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "M6oQE6iD56Xp",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "1cf46c78-ecdd-4c8c-cff2-240fe0701682"
      },
      "source": [
        "model = get_model(hidden_size=32,activation='swish',regularizers=regularizers.l1(0.01))\n",
        "\n",
        "model.compile(loss='categorical_crossentropy', optimizer='rmsprop',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "model.fit(train_images, train_labels, batch_size=batch_size, epochs=nb_epoch,\n",
        "          verbose=1, validation_data=(test_images, test_labels))\n",
        "\n",
        "score = model.evaluate(test_images, test_labels, verbose=1)\n",
        "\n",
        "print(\"Accuracy:\", score[1])"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model_8\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_8 (InputLayer)         (None, 28, 28, 1)         0         \n",
            "_________________________________________________________________\n",
            "flatten_8 (Flatten)          (None, 784)               0         \n",
            "_________________________________________________________________\n",
            "dense_18 (Dense)             (None, 32)                25120     \n",
            "_________________________________________________________________\n",
            "dense_19 (Dense)             (None, 10)                330       \n",
            "=================================================================\n",
            "Total params: 25,450\n",
            "Trainable params: 25,450\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n",
            "Train on 13000 samples, validate on 5724 samples\n",
            "Epoch 1/20\n",
            "13000/13000 [==============================] - 0s 31us/step - loss: 4.6400 - accuracy: 0.7617 - val_loss: 1.9313 - val_accuracy: 0.8183\n",
            "Epoch 2/20\n",
            "13000/13000 [==============================] - 0s 25us/step - loss: 1.7487 - accuracy: 0.8213 - val_loss: 1.6354 - val_accuracy: 0.8235\n",
            "Epoch 3/20\n",
            "13000/13000 [==============================] - 0s 26us/step - loss: 1.5324 - accuracy: 0.8317 - val_loss: 1.4790 - val_accuracy: 0.8368\n",
            "Epoch 4/20\n",
            "13000/13000 [==============================] - 0s 30us/step - loss: 1.3963 - accuracy: 0.8442 - val_loss: 1.3679 - val_accuracy: 0.8417\n",
            "Epoch 5/20\n",
            "13000/13000 [==============================] - 0s 28us/step - loss: 1.3026 - accuracy: 0.8468 - val_loss: 1.2764 - val_accuracy: 0.8464\n",
            "Epoch 6/20\n",
            "13000/13000 [==============================] - 0s 27us/step - loss: 1.2328 - accuracy: 0.8526 - val_loss: 1.2464 - val_accuracy: 0.8457\n",
            "Epoch 7/20\n",
            "13000/13000 [==============================] - 0s 28us/step - loss: 1.1828 - accuracy: 0.8536 - val_loss: 1.1869 - val_accuracy: 0.8491\n",
            "Epoch 8/20\n",
            "13000/13000 [==============================] - 0s 29us/step - loss: 1.1418 - accuracy: 0.8545 - val_loss: 1.1587 - val_accuracy: 0.8522\n",
            "Epoch 9/20\n",
            "13000/13000 [==============================] - 0s 29us/step - loss: 1.1090 - accuracy: 0.8571 - val_loss: 1.1424 - val_accuracy: 0.8601\n",
            "Epoch 10/20\n",
            "13000/13000 [==============================] - 0s 27us/step - loss: 1.0858 - accuracy: 0.8561 - val_loss: 1.0946 - val_accuracy: 0.8573\n",
            "Epoch 11/20\n",
            "13000/13000 [==============================] - 0s 26us/step - loss: 1.0660 - accuracy: 0.8565 - val_loss: 1.0601 - val_accuracy: 0.8613\n",
            "Epoch 12/20\n",
            "13000/13000 [==============================] - 0s 26us/step - loss: 1.0459 - accuracy: 0.8581 - val_loss: 1.1191 - val_accuracy: 0.8475\n",
            "Epoch 13/20\n",
            "13000/13000 [==============================] - 0s 26us/step - loss: 1.0284 - accuracy: 0.8590 - val_loss: 1.0668 - val_accuracy: 0.8534\n",
            "Epoch 14/20\n",
            "13000/13000 [==============================] - 0s 26us/step - loss: 1.0151 - accuracy: 0.8598 - val_loss: 1.0337 - val_accuracy: 0.8637\n",
            "Epoch 15/20\n",
            "13000/13000 [==============================] - 0s 29us/step - loss: 1.0044 - accuracy: 0.8607 - val_loss: 1.0493 - val_accuracy: 0.8546\n",
            "Epoch 16/20\n",
            "13000/13000 [==============================] - 0s 26us/step - loss: 0.9926 - accuracy: 0.8622 - val_loss: 1.0311 - val_accuracy: 0.8594\n",
            "Epoch 17/20\n",
            "13000/13000 [==============================] - 0s 25us/step - loss: 0.9820 - accuracy: 0.8614 - val_loss: 1.0157 - val_accuracy: 0.8620\n",
            "Epoch 18/20\n",
            "13000/13000 [==============================] - 0s 26us/step - loss: 0.9764 - accuracy: 0.8610 - val_loss: 1.0049 - val_accuracy: 0.8618\n",
            "Epoch 19/20\n",
            "13000/13000 [==============================] - 0s 26us/step - loss: 0.9688 - accuracy: 0.8622 - val_loss: 1.0162 - val_accuracy: 0.8574\n",
            "Epoch 20/20\n",
            "13000/13000 [==============================] - 0s 28us/step - loss: 0.9608 - accuracy: 0.8616 - val_loss: 1.0294 - val_accuracy: 0.8546\n",
            "5724/5724 [==============================] - 0s 24us/step\n",
            "Accuracy: 0.8546470999717712\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "5nFtO2cm56Xr"
      },
      "source": [
        "With Xavier Initialization, One hidden layer with 32 input node, Swish, RMSProp, with L2 regularizer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "gJcSOpZH56Xr",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "3867dcac-248a-4cc4-9b57-2977e514b095"
      },
      "source": [
        "model = get_model(hidden_size=32,activation='swish',regularizers=regularizers.l2(0.01))\n",
        "\n",
        "model.compile(loss='categorical_crossentropy', optimizer='rmsprop',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "model.fit(train_images, train_labels, batch_size=batch_size, epochs=nb_epoch,\n",
        "          verbose=1, validation_data=(test_images, test_labels))\n",
        "\n",
        "score = model.evaluate(test_images, test_labels, verbose=1)\n",
        "\n",
        "print(\"Accuracy:\", score[1])"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model_9\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_9 (InputLayer)         (None, 28, 28, 1)         0         \n",
            "_________________________________________________________________\n",
            "flatten_9 (Flatten)          (None, 784)               0         \n",
            "_________________________________________________________________\n",
            "dense_20 (Dense)             (None, 32)                25120     \n",
            "_________________________________________________________________\n",
            "dense_21 (Dense)             (None, 10)                330       \n",
            "=================================================================\n",
            "Total params: 25,450\n",
            "Trainable params: 25,450\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n",
            "Train on 13000 samples, validate on 5724 samples\n",
            "Epoch 1/20\n",
            "13000/13000 [==============================] - 0s 32us/step - loss: 1.1631 - accuracy: 0.8232 - val_loss: 0.7750 - val_accuracy: 0.8763\n",
            "Epoch 2/20\n",
            "13000/13000 [==============================] - 0s 32us/step - loss: 0.6447 - accuracy: 0.8855 - val_loss: 0.5904 - val_accuracy: 0.8857\n",
            "Epoch 3/20\n",
            "13000/13000 [==============================] - 0s 28us/step - loss: 0.5307 - accuracy: 0.8938 - val_loss: 0.5339 - val_accuracy: 0.8917\n",
            "Epoch 4/20\n",
            "13000/13000 [==============================] - 0s 28us/step - loss: 0.4879 - accuracy: 0.8977 - val_loss: 0.5117 - val_accuracy: 0.8901\n",
            "Epoch 5/20\n",
            "13000/13000 [==============================] - 0s 29us/step - loss: 0.4640 - accuracy: 0.9024 - val_loss: 0.4933 - val_accuracy: 0.8947\n",
            "Epoch 6/20\n",
            "13000/13000 [==============================] - 0s 27us/step - loss: 0.4495 - accuracy: 0.9037 - val_loss: 0.4848 - val_accuracy: 0.8936\n",
            "Epoch 7/20\n",
            "13000/13000 [==============================] - 0s 27us/step - loss: 0.4393 - accuracy: 0.9048 - val_loss: 0.4770 - val_accuracy: 0.8940\n",
            "Epoch 8/20\n",
            "13000/13000 [==============================] - 0s 29us/step - loss: 0.4299 - accuracy: 0.9067 - val_loss: 0.4766 - val_accuracy: 0.8966\n",
            "Epoch 9/20\n",
            "13000/13000 [==============================] - 0s 28us/step - loss: 0.4230 - accuracy: 0.9078 - val_loss: 0.4666 - val_accuracy: 0.8973\n",
            "Epoch 10/20\n",
            "13000/13000 [==============================] - 0s 31us/step - loss: 0.4141 - accuracy: 0.9093 - val_loss: 0.4652 - val_accuracy: 0.8964\n",
            "Epoch 11/20\n",
            "13000/13000 [==============================] - 0s 31us/step - loss: 0.4107 - accuracy: 0.9081 - val_loss: 0.4639 - val_accuracy: 0.8987\n",
            "Epoch 12/20\n",
            "13000/13000 [==============================] - 0s 30us/step - loss: 0.4050 - accuracy: 0.9098 - val_loss: 0.4528 - val_accuracy: 0.8999\n",
            "Epoch 13/20\n",
            "13000/13000 [==============================] - 0s 29us/step - loss: 0.3995 - accuracy: 0.9114 - val_loss: 0.4524 - val_accuracy: 0.8990\n",
            "Epoch 14/20\n",
            "13000/13000 [==============================] - 0s 27us/step - loss: 0.3962 - accuracy: 0.9128 - val_loss: 0.4679 - val_accuracy: 0.8905\n",
            "Epoch 15/20\n",
            "13000/13000 [==============================] - 0s 26us/step - loss: 0.3936 - accuracy: 0.9118 - val_loss: 0.4485 - val_accuracy: 0.9013\n",
            "Epoch 16/20\n",
            "13000/13000 [==============================] - 0s 25us/step - loss: 0.3894 - accuracy: 0.9139 - val_loss: 0.4398 - val_accuracy: 0.9016\n",
            "Epoch 17/20\n",
            "13000/13000 [==============================] - 0s 26us/step - loss: 0.3862 - accuracy: 0.9145 - val_loss: 0.4589 - val_accuracy: 0.8945\n",
            "Epoch 18/20\n",
            "13000/13000 [==============================] - 0s 25us/step - loss: 0.3827 - accuracy: 0.9168 - val_loss: 0.4389 - val_accuracy: 0.9004\n",
            "Epoch 19/20\n",
            "13000/13000 [==============================] - 0s 26us/step - loss: 0.3808 - accuracy: 0.9143 - val_loss: 0.4605 - val_accuracy: 0.8941\n",
            "Epoch 20/20\n",
            "13000/13000 [==============================] - 0s 25us/step - loss: 0.3772 - accuracy: 0.9168 - val_loss: 0.4566 - val_accuracy: 0.8980\n",
            "5724/5724 [==============================] - 0s 21us/step\n",
            "Accuracy: 0.8979734182357788\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "3YmrB4Ep56Xt"
      },
      "source": [
        "With Xavier Initialization, Two hidden layer with each layer contains 128 input node, Swish, RMSProp, without regularizer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "c115bc83-6b7f-4cf2-8879-969f2b8f2fab",
        "id": "nOLarrTa56Xt",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "model = get_model2(hidden_size=128,activation='swish')\n",
        "\n",
        "model.compile(loss='categorical_crossentropy', optimizer='rmsprop',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "model.fit(train_images, train_labels, batch_size=batch_size, epochs=nb_epoch,\n",
        "          verbose=1, validation_data=(test_images, test_labels))\n",
        "\n",
        "score = model.evaluate(test_images, test_labels, verbose=1)\n",
        "\n",
        "print(\"Accuracy:\", score[1])\t  "
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model_10\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_10 (InputLayer)        (None, 28, 28, 1)         0         \n",
            "_________________________________________________________________\n",
            "flatten_10 (Flatten)         (None, 784)               0         \n",
            "_________________________________________________________________\n",
            "dense_22 (Dense)             (None, 128)               100480    \n",
            "_________________________________________________________________\n",
            "dense_23 (Dense)             (None, 128)               16512     \n",
            "_________________________________________________________________\n",
            "dense_24 (Dense)             (None, 10)                1290      \n",
            "=================================================================\n",
            "Total params: 118,282\n",
            "Trainable params: 118,282\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n",
            "Train on 13000 samples, validate on 5724 samples\n",
            "Epoch 1/20\n",
            "13000/13000 [==============================] - 1s 54us/step - loss: 0.4960 - accuracy: 0.8625 - val_loss: 0.3629 - val_accuracy: 0.8957\n",
            "Epoch 2/20\n",
            "13000/13000 [==============================] - 1s 45us/step - loss: 0.2945 - accuracy: 0.9099 - val_loss: 0.3464 - val_accuracy: 0.8983\n",
            "Epoch 3/20\n",
            "13000/13000 [==============================] - 1s 48us/step - loss: 0.2413 - accuracy: 0.9242 - val_loss: 0.3189 - val_accuracy: 0.9106\n",
            "Epoch 4/20\n",
            "13000/13000 [==============================] - 1s 49us/step - loss: 0.2008 - accuracy: 0.9375 - val_loss: 0.3427 - val_accuracy: 0.9051\n",
            "Epoch 5/20\n",
            "13000/13000 [==============================] - 1s 47us/step - loss: 0.1688 - accuracy: 0.9446 - val_loss: 0.3230 - val_accuracy: 0.9128\n",
            "Epoch 6/20\n",
            "13000/13000 [==============================] - 1s 51us/step - loss: 0.1382 - accuracy: 0.9561 - val_loss: 0.3551 - val_accuracy: 0.9051\n",
            "Epoch 7/20\n",
            "13000/13000 [==============================] - 1s 50us/step - loss: 0.1158 - accuracy: 0.9651 - val_loss: 0.3580 - val_accuracy: 0.9102\n",
            "Epoch 8/20\n",
            "13000/13000 [==============================] - 1s 49us/step - loss: 0.0937 - accuracy: 0.9702 - val_loss: 0.3645 - val_accuracy: 0.9165\n",
            "Epoch 9/20\n",
            "13000/13000 [==============================] - 1s 50us/step - loss: 0.0765 - accuracy: 0.9776 - val_loss: 0.3754 - val_accuracy: 0.9149\n",
            "Epoch 10/20\n",
            "13000/13000 [==============================] - 1s 46us/step - loss: 0.0645 - accuracy: 0.9800 - val_loss: 0.4183 - val_accuracy: 0.9128\n",
            "Epoch 11/20\n",
            "13000/13000 [==============================] - 1s 46us/step - loss: 0.0541 - accuracy: 0.9838 - val_loss: 0.4361 - val_accuracy: 0.9140\n",
            "Epoch 12/20\n",
            "13000/13000 [==============================] - 1s 46us/step - loss: 0.0453 - accuracy: 0.9874 - val_loss: 0.4305 - val_accuracy: 0.9198\n",
            "Epoch 13/20\n",
            "13000/13000 [==============================] - 1s 46us/step - loss: 0.0414 - accuracy: 0.9878 - val_loss: 0.4550 - val_accuracy: 0.9188\n",
            "Epoch 14/20\n",
            "13000/13000 [==============================] - 1s 48us/step - loss: 0.0357 - accuracy: 0.9888 - val_loss: 0.4608 - val_accuracy: 0.9191\n",
            "Epoch 15/20\n",
            "13000/13000 [==============================] - 1s 46us/step - loss: 0.0297 - accuracy: 0.9916 - val_loss: 0.5204 - val_accuracy: 0.9149\n",
            "Epoch 16/20\n",
            "13000/13000 [==============================] - 1s 48us/step - loss: 0.0269 - accuracy: 0.9918 - val_loss: 0.5695 - val_accuracy: 0.9119\n",
            "Epoch 17/20\n",
            "13000/13000 [==============================] - 1s 47us/step - loss: 0.0262 - accuracy: 0.9921 - val_loss: 0.5268 - val_accuracy: 0.9167\n",
            "Epoch 18/20\n",
            "13000/13000 [==============================] - 1s 49us/step - loss: 0.0221 - accuracy: 0.9929 - val_loss: 0.5753 - val_accuracy: 0.9168\n",
            "Epoch 19/20\n",
            "13000/13000 [==============================] - 1s 49us/step - loss: 0.0221 - accuracy: 0.9935 - val_loss: 0.5543 - val_accuracy: 0.9202\n",
            "Epoch 20/20\n",
            "13000/13000 [==============================] - 1s 48us/step - loss: 0.0197 - accuracy: 0.9937 - val_loss: 0.6106 - val_accuracy: 0.9137\n",
            "5724/5724 [==============================] - 0s 28us/step\n",
            "Accuracy: 0.9136967062950134\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "kpldpsbZ56Xv"
      },
      "source": [
        "With Xavier Initialization, Two hidden layer with each layer contains 128 input node, Swish, RMSProp, with L1 regularizer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "N-yd-IRQ56Xv",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "dd882d15-3288-4c9b-bbf4-1d8dc3cb1e8d"
      },
      "source": [
        "model = get_model2(hidden_size=128,regularizers=regularizers.l1(0.01))\n",
        "\n",
        "model.compile(loss='categorical_crossentropy', optimizer='rmsprop',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "model.fit(train_images, train_labels, batch_size=batch_size, epochs=nb_epoch,\n",
        "          verbose=1, validation_data=(test_images, test_labels))\n",
        "\n",
        "score = model.evaluate(test_images, test_labels, verbose=1)\n",
        "\n",
        "print(\"Accuracy:\", score[1])"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model_11\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_11 (InputLayer)        (None, 28, 28, 1)         0         \n",
            "_________________________________________________________________\n",
            "flatten_11 (Flatten)         (None, 784)               0         \n",
            "_________________________________________________________________\n",
            "dense_25 (Dense)             (None, 128)               100480    \n",
            "_________________________________________________________________\n",
            "dense_26 (Dense)             (None, 128)               16512     \n",
            "_________________________________________________________________\n",
            "dense_27 (Dense)             (None, 10)                1290      \n",
            "=================================================================\n",
            "Total params: 118,282\n",
            "Trainable params: 118,282\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n",
            "Train on 13000 samples, validate on 5724 samples\n",
            "Epoch 1/20\n",
            "13000/13000 [==============================] - 1s 59us/step - loss: 16.3465 - accuracy: 0.5001 - val_loss: 3.5692 - val_accuracy: 0.5412\n",
            "Epoch 2/20\n",
            "13000/13000 [==============================] - 1s 53us/step - loss: 2.4956 - accuracy: 0.6111 - val_loss: 2.1929 - val_accuracy: 0.6578\n",
            "Epoch 3/20\n",
            "13000/13000 [==============================] - 1s 52us/step - loss: 2.0973 - accuracy: 0.6812 - val_loss: 2.0540 - val_accuracy: 0.6932\n",
            "Epoch 4/20\n",
            "13000/13000 [==============================] - 1s 52us/step - loss: 1.9780 - accuracy: 0.7121 - val_loss: 1.9478 - val_accuracy: 0.7547\n",
            "Epoch 5/20\n",
            "13000/13000 [==============================] - 1s 55us/step - loss: 1.8972 - accuracy: 0.7663 - val_loss: 1.8854 - val_accuracy: 0.7725\n",
            "Epoch 6/20\n",
            "13000/13000 [==============================] - 1s 52us/step - loss: 1.8316 - accuracy: 0.7982 - val_loss: 1.8341 - val_accuracy: 0.8077\n",
            "Epoch 7/20\n",
            "13000/13000 [==============================] - 1s 50us/step - loss: 1.7793 - accuracy: 0.8228 - val_loss: 1.7629 - val_accuracy: 0.8342\n",
            "Epoch 8/20\n",
            "13000/13000 [==============================] - 1s 49us/step - loss: 1.7320 - accuracy: 0.8331 - val_loss: 1.7332 - val_accuracy: 0.8354\n",
            "Epoch 9/20\n",
            "13000/13000 [==============================] - 1s 52us/step - loss: 1.6989 - accuracy: 0.8375 - val_loss: 1.6912 - val_accuracy: 0.8436\n",
            "Epoch 10/20\n",
            "13000/13000 [==============================] - 1s 51us/step - loss: 1.6713 - accuracy: 0.8416 - val_loss: 1.6842 - val_accuracy: 0.8391\n",
            "Epoch 11/20\n",
            "13000/13000 [==============================] - 1s 51us/step - loss: 1.6489 - accuracy: 0.8425 - val_loss: 1.6613 - val_accuracy: 0.8405\n",
            "Epoch 12/20\n",
            "13000/13000 [==============================] - 1s 48us/step - loss: 1.6295 - accuracy: 0.8458 - val_loss: 1.6267 - val_accuracy: 0.8485\n",
            "Epoch 13/20\n",
            "13000/13000 [==============================] - 1s 50us/step - loss: 1.6141 - accuracy: 0.8471 - val_loss: 1.6340 - val_accuracy: 0.8428\n",
            "Epoch 14/20\n",
            "13000/13000 [==============================] - 1s 51us/step - loss: 1.6005 - accuracy: 0.8496 - val_loss: 1.6168 - val_accuracy: 0.8499\n",
            "Epoch 15/20\n",
            "13000/13000 [==============================] - 1s 49us/step - loss: 1.5867 - accuracy: 0.8505 - val_loss: 1.5999 - val_accuracy: 0.8506\n",
            "Epoch 16/20\n",
            "13000/13000 [==============================] - 1s 49us/step - loss: 1.5755 - accuracy: 0.8498 - val_loss: 1.6026 - val_accuracy: 0.8464\n",
            "Epoch 17/20\n",
            "13000/13000 [==============================] - 1s 50us/step - loss: 1.5636 - accuracy: 0.8507 - val_loss: 1.6197 - val_accuracy: 0.8408\n",
            "Epoch 18/20\n",
            "13000/13000 [==============================] - 1s 49us/step - loss: 1.5535 - accuracy: 0.8548 - val_loss: 1.5853 - val_accuracy: 0.8456\n",
            "Epoch 19/20\n",
            "13000/13000 [==============================] - 1s 51us/step - loss: 1.5432 - accuracy: 0.8537 - val_loss: 1.5601 - val_accuracy: 0.8529\n",
            "Epoch 20/20\n",
            "13000/13000 [==============================] - 1s 53us/step - loss: 1.5376 - accuracy: 0.8541 - val_loss: 1.5897 - val_accuracy: 0.8351\n",
            "5724/5724 [==============================] - 0s 29us/step\n",
            "Accuracy: 0.8350803852081299\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "EI_ugAky56Xx"
      },
      "source": [
        "With Xavier Initialization, Two hidden layer with each layer contains 128 input node, Swish, RMSProp, with L2\n",
        "regularizer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "E30bQUIi56Xy",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "8929e441-fe38-4af9-b557-c915f156948d"
      },
      "source": [
        "model = get_model2(hidden_size=128,regularizers=regularizers.l2(0.01))\n",
        "\n",
        "model.compile(loss='categorical_crossentropy', optimizer='rmsprop',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "model.fit(train_images, train_labels, batch_size=batch_size, epochs=nb_epoch,\n",
        "          verbose=1, validation_data=(test_images, test_labels))\n",
        "\n",
        "score = model.evaluate(test_images, test_labels, verbose=1)\n",
        "\n",
        "print(\"Accuracy:\", score[1])"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model_12\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_12 (InputLayer)        (None, 28, 28, 1)         0         \n",
            "_________________________________________________________________\n",
            "flatten_12 (Flatten)         (None, 784)               0         \n",
            "_________________________________________________________________\n",
            "dense_28 (Dense)             (None, 128)               100480    \n",
            "_________________________________________________________________\n",
            "dense_29 (Dense)             (None, 128)               16512     \n",
            "_________________________________________________________________\n",
            "dense_30 (Dense)             (None, 10)                1290      \n",
            "=================================================================\n",
            "Total params: 118,282\n",
            "Trainable params: 118,282\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n",
            "Train on 13000 samples, validate on 5724 samples\n",
            "Epoch 1/20\n",
            "13000/13000 [==============================] - 1s 49us/step - loss: 2.2842 - accuracy: 0.8510 - val_loss: 1.1331 - val_accuracy: 0.8819\n",
            "Epoch 2/20\n",
            "13000/13000 [==============================] - 1s 44us/step - loss: 0.8161 - accuracy: 0.8938 - val_loss: 0.6658 - val_accuracy: 0.8961\n",
            "Epoch 3/20\n",
            "13000/13000 [==============================] - 1s 42us/step - loss: 0.5972 - accuracy: 0.8946 - val_loss: 0.5888 - val_accuracy: 0.8901\n",
            "Epoch 4/20\n",
            "13000/13000 [==============================] - 1s 45us/step - loss: 0.5434 - accuracy: 0.8971 - val_loss: 0.6094 - val_accuracy: 0.8599\n",
            "Epoch 5/20\n",
            "13000/13000 [==============================] - 1s 46us/step - loss: 0.5147 - accuracy: 0.9021 - val_loss: 0.5599 - val_accuracy: 0.8866\n",
            "Epoch 6/20\n",
            "13000/13000 [==============================] - 1s 45us/step - loss: 0.4976 - accuracy: 0.9035 - val_loss: 0.5226 - val_accuracy: 0.8987\n",
            "Epoch 7/20\n",
            "13000/13000 [==============================] - 1s 44us/step - loss: 0.4830 - accuracy: 0.9053 - val_loss: 0.5928 - val_accuracy: 0.8601\n",
            "Epoch 8/20\n",
            "13000/13000 [==============================] - 1s 43us/step - loss: 0.4698 - accuracy: 0.9095 - val_loss: 0.5241 - val_accuracy: 0.8936\n",
            "Epoch 9/20\n",
            "13000/13000 [==============================] - 1s 43us/step - loss: 0.4586 - accuracy: 0.9088 - val_loss: 0.5270 - val_accuracy: 0.8884\n",
            "Epoch 10/20\n",
            "13000/13000 [==============================] - 1s 44us/step - loss: 0.4518 - accuracy: 0.9113 - val_loss: 0.4972 - val_accuracy: 0.8929\n",
            "Epoch 11/20\n",
            "13000/13000 [==============================] - 1s 45us/step - loss: 0.4414 - accuracy: 0.9122 - val_loss: 0.4911 - val_accuracy: 0.9022\n",
            "Epoch 12/20\n",
            "13000/13000 [==============================] - 1s 43us/step - loss: 0.4312 - accuracy: 0.9147 - val_loss: 0.4881 - val_accuracy: 0.8985\n",
            "Epoch 13/20\n",
            "13000/13000 [==============================] - 1s 42us/step - loss: 0.4255 - accuracy: 0.9162 - val_loss: 0.4773 - val_accuracy: 0.9043\n",
            "Epoch 14/20\n",
            "13000/13000 [==============================] - 1s 44us/step - loss: 0.4178 - accuracy: 0.9172 - val_loss: 0.4732 - val_accuracy: 0.9041\n",
            "Epoch 15/20\n",
            "13000/13000 [==============================] - 1s 42us/step - loss: 0.4131 - accuracy: 0.9182 - val_loss: 0.4765 - val_accuracy: 0.9008\n",
            "Epoch 16/20\n",
            "13000/13000 [==============================] - 1s 42us/step - loss: 0.4082 - accuracy: 0.9184 - val_loss: 0.4862 - val_accuracy: 0.8978\n",
            "Epoch 17/20\n",
            "13000/13000 [==============================] - 1s 42us/step - loss: 0.4025 - accuracy: 0.9188 - val_loss: 0.4597 - val_accuracy: 0.9055\n",
            "Epoch 18/20\n",
            "13000/13000 [==============================] - 1s 43us/step - loss: 0.3969 - accuracy: 0.9236 - val_loss: 0.4698 - val_accuracy: 0.9050\n",
            "Epoch 19/20\n",
            "13000/13000 [==============================] - 1s 43us/step - loss: 0.3944 - accuracy: 0.9212 - val_loss: 0.4622 - val_accuracy: 0.9076\n",
            "Epoch 20/20\n",
            "13000/13000 [==============================] - 1s 42us/step - loss: 0.3907 - accuracy: 0.9246 - val_loss: 0.4552 - val_accuracy: 0.9071\n",
            "5724/5724 [==============================] - 0s 31us/step\n",
            "Accuracy: 0.9070580005645752\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F29jFmyHkoHo",
        "colab_type": "text"
      },
      "source": [
        "To save the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GzllSm3SS292",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.save(\"model.h5\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R-lghkijkrzP",
        "colab_type": "text"
      },
      "source": [
        "To load the model and run inference"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1l6x0MXsUz1a",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 340
        },
        "outputId": "74aa853f-1aa1-460d-e3fe-56373d04a44c"
      },
      "source": [
        "# load and evaluate a saved model\n",
        "from numpy import loadtxt\n",
        "from keras.models import load_model\n",
        "\n",
        "# load model\n",
        "model = load_model('model.h5')\n",
        "# summarize model.\n",
        "model.summary()\n",
        "# load dataset\n",
        "_,_,test_images, test_labels  = load_data()\n",
        "\n",
        "# evaluate the model\n",
        "score = model.evaluate(test_images, test_labels, verbose=0)\n",
        "print(\"%s: %.2f%%\" % (model.metrics_names[1], score[1]*100))"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model_12\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_12 (InputLayer)        (None, 28, 28, 1)         0         \n",
            "_________________________________________________________________\n",
            "flatten_12 (Flatten)         (None, 784)               0         \n",
            "_________________________________________________________________\n",
            "dense_28 (Dense)             (None, 128)               100480    \n",
            "_________________________________________________________________\n",
            "dense_29 (Dense)             (None, 128)               16512     \n",
            "_________________________________________________________________\n",
            "dense_30 (Dense)             (None, 10)                1290      \n",
            "=================================================================\n",
            "Total params: 118,282\n",
            "Trainable params: 118,282\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "accuracy: 92.56%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z9X1lCeDUwEN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# make a prediction for a new image.\n",
        "from keras.preprocessing.image import load_img\n",
        "from keras.preprocessing.image import img_to_array\n",
        "from keras.models import load_model\n",
        "\n",
        "# load and prepare the image\n",
        "def load_image(filename):\n",
        "\t# load the image\n",
        "\timg = load_img(filename, grayscale=True, target_size=(28, 28))\n",
        "\t# convert to array\n",
        "\timg = img_to_array(img)\n",
        "\t# reshape into a single sample with 1 channel\n",
        "\timg = img.reshape(1, 28, 28, 1)\n",
        "\t# prepare pixel data\n",
        "\timg = img.astype('float32')\n",
        "\timg = img / 255.0\n",
        "\treturn img\n",
        "\n",
        "# load an image and predict the class\n",
        "def run_example():\n",
        "\t# load the image\n",
        "\timg = load_image('sample_image.png')\n",
        "\t# load model\n",
        "\tmodel = load_model('model.h5')\n",
        "\t# predict the class\n",
        "\tresult = model.predict_classes(img)\n",
        "\tprint(result[0])\n",
        "\n",
        "# entry point, run the example\n",
        "#run_example()"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}