{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "HW3.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "goxaWt3QA8iU",
        "colab_type": "text"
      },
      "source": [
        "Number 9"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "llHeFlc8PSyQ",
        "colab_type": "code",
        "outputId": "6fe0722f-10d1-49a5-cd38-58a533bbf707",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 530
        }
      },
      "source": [
        "# Import required libraries\n",
        "import pandas as pd\n",
        "import numpy as np \n",
        "import matplotlib.pyplot as plt\n",
        "import sklearn\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "from sklearn.neural_network import MLPRegressor\n",
        "\n",
        "# Import necessary modules\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import mean_squared_error\n",
        "from math import sqrt\n",
        "from sklearn.metrics import r2_score\n",
        "\n",
        "df = pd.read_csv('diabetes.csv') \n",
        "print(df.shape)\n",
        "df.describe().transpose()\n",
        "\n",
        "target_column = ['Outcome'] \n",
        "predictors = list(set(list(df.columns))-set(target_column))\n",
        "df[predictors] = df[predictors]/df[predictors].max()\n",
        "df.describe().transpose()\n",
        "\n",
        "X = df[predictors].values\n",
        "y = df[target_column].values\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.30, random_state=40)\n",
        "print(X_train.shape); print(X_test.shape)\n",
        "\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "\n",
        "mlp = MLPClassifier(hidden_layer_sizes=(8,8,8), activation='relu', solver='adam', max_iter=500)\n",
        "mlp.fit(X_train,y_train)\n",
        "\n",
        "predict_train = mlp.predict(X_train)\n",
        "predict_test = mlp.predict(X_test)\n",
        "\n",
        "from sklearn.metrics import classification_report,confusion_matrix\n",
        "print(confusion_matrix(y_train,predict_train))\n",
        "print(classification_report(y_train,predict_train))\n",
        "\n",
        "print(confusion_matrix(y_test,predict_test))\n",
        "print(classification_report(y_test,predict_test))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(768, 9)\n",
            "(537, 8)\n",
            "(231, 8)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:934: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[[322  36]\n",
            " [ 67 112]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.83      0.90      0.86       358\n",
            "           1       0.76      0.63      0.69       179\n",
            "\n",
            "    accuracy                           0.81       537\n",
            "   macro avg       0.79      0.76      0.77       537\n",
            "weighted avg       0.80      0.81      0.80       537\n",
            "\n",
            "[[126  16]\n",
            " [ 38  51]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.77      0.89      0.82       142\n",
            "           1       0.76      0.57      0.65        89\n",
            "\n",
            "    accuracy                           0.77       231\n",
            "   macro avg       0.76      0.73      0.74       231\n",
            "weighted avg       0.77      0.77      0.76       231\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PyU2U-MMw9aW",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "d8fef631-e34c-4993-f31f-37a40ff584c9"
      },
      "source": [
        "from __future__ import print_function\n",
        "\n",
        "import tensorflow.keras\n",
        "from tensorflow.keras.datasets import mnist\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Dropout\n",
        "from tensorflow.keras.optimizers import RMSprop\n",
        "import pandas as pd\n",
        "\n",
        "batch_size = 128\n",
        "num_classes = 2\n",
        "epochs = 20\n",
        "\n",
        "df = pd.read_csv('diabetes.csv') \n",
        "print(df.shape)\n",
        "df.describe().transpose()\n",
        "\n",
        "target_column = ['Outcome'] \n",
        "predictors = list(set(list(df.columns))-set(target_column))\n",
        "df[predictors] = df[predictors]/df[predictors].max()\n",
        "df.describe().transpose()\n",
        "\n",
        "X = df[predictors].values\n",
        "y = df[target_column].values\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.30, random_state=40)\n",
        "print(X_train.shape); print(X_test.shape)\n",
        "\n",
        "# convert class vectors to binary class matrices\n",
        "y_train = keras.utils.to_categorical(y_train, num_classes)\n",
        "y_test = keras.utils.to_categorical(y_test, num_classes)\n",
        "\n",
        "\n",
        "model = Sequential()\n",
        "model.add(Dense(512, activation='relu', input_shape=(8,)))\n",
        "model.add(Dropout(0.2))\n",
        "model.add(Dense(512, activation='relu'))\n",
        "model.add(Dropout(0.2))\n",
        "model.add(Dense(num_classes, activation='softmax'))\n",
        "\n",
        "model.summary()\n",
        "\n",
        "model.compile(loss='binary_crossentropy',\n",
        "              optimizer=RMSprop(),\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "history = model.fit(X_train, y_train,\n",
        "                    batch_size=batch_size,\n",
        "                    epochs=epochs,\n",
        "                    verbose=1,\n",
        "                    validation_data=(X_test, y_test))\n",
        "score = model.evaluate(X_test, y_test, verbose=0)\n",
        "print('Test loss:', score[0])\n",
        "print('Test accuracy:', score[1])"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(768, 9)\n",
            "(537, 8)\n",
            "(231, 8)\n",
            "Model: \"sequential_7\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense_21 (Dense)             (None, 512)               4608      \n",
            "_________________________________________________________________\n",
            "dropout_14 (Dropout)         (None, 512)               0         \n",
            "_________________________________________________________________\n",
            "dense_22 (Dense)             (None, 512)               262656    \n",
            "_________________________________________________________________\n",
            "dropout_15 (Dropout)         (None, 512)               0         \n",
            "_________________________________________________________________\n",
            "dense_23 (Dense)             (None, 2)                 1026      \n",
            "=================================================================\n",
            "Total params: 268,290\n",
            "Trainable params: 268,290\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/20\n",
            "5/5 [==============================] - 0s 30ms/step - loss: 0.6756 - accuracy: 0.6629 - val_loss: 0.6580 - val_accuracy: 0.6320\n",
            "Epoch 2/20\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.6192 - accuracy: 0.6778 - val_loss: 0.6813 - val_accuracy: 0.6277\n",
            "Epoch 3/20\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 0.6360 - accuracy: 0.6741 - val_loss: 0.7003 - val_accuracy: 0.4978\n",
            "Epoch 4/20\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 0.6376 - accuracy: 0.6369 - val_loss: 0.6090 - val_accuracy: 0.6926\n",
            "Epoch 5/20\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 0.5966 - accuracy: 0.7132 - val_loss: 0.6016 - val_accuracy: 0.6840\n",
            "Epoch 6/20\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 0.5849 - accuracy: 0.7169 - val_loss: 0.5802 - val_accuracy: 0.7143\n",
            "Epoch 7/20\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 0.5706 - accuracy: 0.7169 - val_loss: 0.6115 - val_accuracy: 0.6797\n",
            "Epoch 8/20\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 0.5876 - accuracy: 0.6983 - val_loss: 0.6021 - val_accuracy: 0.6926\n",
            "Epoch 9/20\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.5507 - accuracy: 0.7337 - val_loss: 0.5615 - val_accuracy: 0.7403\n",
            "Epoch 10/20\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 0.5541 - accuracy: 0.7374 - val_loss: 0.5956 - val_accuracy: 0.6623\n",
            "Epoch 11/20\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.5417 - accuracy: 0.7132 - val_loss: 0.6240 - val_accuracy: 0.6797\n",
            "Epoch 12/20\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 0.5729 - accuracy: 0.7486 - val_loss: 0.5566 - val_accuracy: 0.7186\n",
            "Epoch 13/20\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 0.5335 - accuracy: 0.7523 - val_loss: 0.5411 - val_accuracy: 0.7273\n",
            "Epoch 14/20\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 0.5530 - accuracy: 0.7598 - val_loss: 0.5778 - val_accuracy: 0.6667\n",
            "Epoch 15/20\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 0.5138 - accuracy: 0.7467 - val_loss: 0.6416 - val_accuracy: 0.6667\n",
            "Epoch 16/20\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 0.5222 - accuracy: 0.7542 - val_loss: 0.5758 - val_accuracy: 0.6710\n",
            "Epoch 17/20\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 0.5188 - accuracy: 0.7467 - val_loss: 0.5786 - val_accuracy: 0.6623\n",
            "Epoch 18/20\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 0.5160 - accuracy: 0.7505 - val_loss: 0.5223 - val_accuracy: 0.7359\n",
            "Epoch 19/20\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 0.5140 - accuracy: 0.7579 - val_loss: 0.6977 - val_accuracy: 0.6580\n",
            "Epoch 20/20\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 0.5089 - accuracy: 0.7654 - val_loss: 0.5115 - val_accuracy: 0.7403\n",
            "Test loss: 0.4976322054862976\n",
            "Test accuracy: 0.7402597665786743\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0G_nre_LBAK6",
        "colab_type": "text"
      },
      "source": [
        "Number 10"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mIrJ7pBeRPpB",
        "colab_type": "code",
        "outputId": "2d5fb7f5-c946-4c2f-c18b-6c68dc4645cc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "from __future__ import print_function\n",
        "\n",
        "import tensorflow.keras\n",
        "from tensorflow.keras.datasets import mnist\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Dropout\n",
        "from tensorflow.keras.optimizers import RMSprop\n",
        "\n",
        "batch_size = 128\n",
        "num_classes = 10\n",
        "epochs = 20\n",
        "\n",
        "# the data, split between train and test sets\n",
        "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
        "\n",
        "x_train = x_train.reshape(60000, 784)\n",
        "x_test = x_test.reshape(10000, 784)\n",
        "x_train = x_train.astype('float32')\n",
        "x_test = x_test.astype('float32')\n",
        "x_train /= 255\n",
        "x_test /= 255\n",
        "print(x_train.shape[0], 'train samples')\n",
        "print(x_test.shape[0], 'test samples')\n",
        "\n",
        "# convert class vectors to binary class matrices\n",
        "y_train = keras.utils.to_categorical(y_train, num_classes)\n",
        "y_test = keras.utils.to_categorical(y_test, num_classes)\n",
        "\n",
        "model = Sequential()\n",
        "model.add(Dense(512, activation='relu', input_shape=(784,)))\n",
        "model.add(Dropout(0.2))\n",
        "model.add(Dense(512, activation='relu'))\n",
        "model.add(Dropout(0.2))\n",
        "model.add(Dense(num_classes, activation='softmax'))\n",
        "\n",
        "model.summary()\n",
        "\n",
        "model.compile(loss='categorical_crossentropy',\n",
        "              optimizer=RMSprop(),\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "history = model.fit(x_train, y_train,\n",
        "                    batch_size=batch_size,\n",
        "                    epochs=epochs,\n",
        "                    verbose=1,\n",
        "                    validation_data=(x_test, y_test))\n",
        "score = model.evaluate(x_test, y_test, verbose=0)\n",
        "print('Test loss:', score[0])\n",
        "print('Test accuracy:', score[1])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "60000 train samples\n",
            "10000 test samples\n",
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense (Dense)                (None, 512)               401920    \n",
            "_________________________________________________________________\n",
            "dropout (Dropout)            (None, 512)               0         \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 512)               262656    \n",
            "_________________________________________________________________\n",
            "dropout_1 (Dropout)          (None, 512)               0         \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 10)                5130      \n",
            "=================================================================\n",
            "Total params: 669,706\n",
            "Trainable params: 669,706\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/20\n",
            "469/469 [==============================] - 8s 18ms/step - loss: 0.2495 - accuracy: 0.9247 - val_loss: 0.0977 - val_accuracy: 0.9687\n",
            "Epoch 2/20\n",
            "469/469 [==============================] - 8s 18ms/step - loss: 0.1025 - accuracy: 0.9686 - val_loss: 0.0869 - val_accuracy: 0.9727\n",
            "Epoch 3/20\n",
            "469/469 [==============================] - 8s 18ms/step - loss: 0.0742 - accuracy: 0.9773 - val_loss: 0.0898 - val_accuracy: 0.9740\n",
            "Epoch 4/20\n",
            "469/469 [==============================] - 8s 17ms/step - loss: 0.0610 - accuracy: 0.9817 - val_loss: 0.0802 - val_accuracy: 0.9783\n",
            "Epoch 5/20\n",
            "469/469 [==============================] - 8s 18ms/step - loss: 0.0501 - accuracy: 0.9845 - val_loss: 0.0742 - val_accuracy: 0.9802\n",
            "Epoch 6/20\n",
            "469/469 [==============================] - 8s 18ms/step - loss: 0.0446 - accuracy: 0.9863 - val_loss: 0.0625 - val_accuracy: 0.9834\n",
            "Epoch 7/20\n",
            "469/469 [==============================] - 8s 17ms/step - loss: 0.0374 - accuracy: 0.9886 - val_loss: 0.0785 - val_accuracy: 0.9818\n",
            "Epoch 8/20\n",
            "469/469 [==============================] - 8s 17ms/step - loss: 0.0314 - accuracy: 0.9902 - val_loss: 0.0914 - val_accuracy: 0.9811\n",
            "Epoch 9/20\n",
            "469/469 [==============================] - 8s 17ms/step - loss: 0.0302 - accuracy: 0.9913 - val_loss: 0.0833 - val_accuracy: 0.9840\n",
            "Epoch 10/20\n",
            "469/469 [==============================] - 8s 17ms/step - loss: 0.0270 - accuracy: 0.9917 - val_loss: 0.0856 - val_accuracy: 0.9851\n",
            "Epoch 11/20\n",
            "469/469 [==============================] - 8s 18ms/step - loss: 0.0263 - accuracy: 0.9925 - val_loss: 0.0904 - val_accuracy: 0.9838\n",
            "Epoch 12/20\n",
            "469/469 [==============================] - 8s 17ms/step - loss: 0.0249 - accuracy: 0.9930 - val_loss: 0.0952 - val_accuracy: 0.9829\n",
            "Epoch 13/20\n",
            "469/469 [==============================] - 8s 17ms/step - loss: 0.0215 - accuracy: 0.9936 - val_loss: 0.0884 - val_accuracy: 0.9837\n",
            "Epoch 14/20\n",
            "469/469 [==============================] - 8s 17ms/step - loss: 0.0226 - accuracy: 0.9940 - val_loss: 0.1022 - val_accuracy: 0.9825\n",
            "Epoch 15/20\n",
            "469/469 [==============================] - 8s 18ms/step - loss: 0.0207 - accuracy: 0.9944 - val_loss: 0.1082 - val_accuracy: 0.9819\n",
            "Epoch 16/20\n",
            "469/469 [==============================] - 8s 17ms/step - loss: 0.0190 - accuracy: 0.9949 - val_loss: 0.1062 - val_accuracy: 0.9844\n",
            "Epoch 17/20\n",
            "469/469 [==============================] - 8s 17ms/step - loss: 0.0208 - accuracy: 0.9946 - val_loss: 0.1185 - val_accuracy: 0.9818\n",
            "Epoch 18/20\n",
            "469/469 [==============================] - 8s 17ms/step - loss: 0.0181 - accuracy: 0.9952 - val_loss: 0.1242 - val_accuracy: 0.9829\n",
            "Epoch 19/20\n",
            "469/469 [==============================] - 8s 17ms/step - loss: 0.0180 - accuracy: 0.9955 - val_loss: 0.1174 - val_accuracy: 0.9825\n",
            "Epoch 20/20\n",
            "469/469 [==============================] - 8s 17ms/step - loss: 0.0150 - accuracy: 0.9958 - val_loss: 0.1414 - val_accuracy: 0.9832\n",
            "Test loss: 0.14275647699832916\n",
            "Test accuracy: 0.9832000136375427\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WpBvuktQw_OJ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 935
        },
        "outputId": "f9483a76-b41a-4310-de23-9f355d78981d"
      },
      "source": [
        "# Import required libraries\n",
        "import pandas as pd\n",
        "import numpy as np \n",
        "import matplotlib.pyplot as plt\n",
        "import sklearn\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "from sklearn.neural_network import MLPRegressor\n",
        "\n",
        "import tensorflow.keras\n",
        "from tensorflow.keras.datasets import mnist\n",
        "\n",
        "# Import necessary modules\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import mean_squared_error\n",
        "from math import sqrt\n",
        "from sklearn.metrics import r2_score\n",
        "\n",
        "# df = pd.read_csv('diabetes.csv') \n",
        "# print(df.shape)\n",
        "# df.describe().transpose()\n",
        "\n",
        "# target_column = ['Outcome'] \n",
        "# predictors = list(set(list(df.columns))-set(target_column))\n",
        "# df[predictors] = df[predictors]/df[predictors].max()\n",
        "# df.describe().transpose()\n",
        "\n",
        "# X = df[predictors].values\n",
        "# y = df[target_column].values\n",
        "\n",
        "# X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.30, random_state=40)\n",
        "# print(X_train.shape); print(X_test.shape)\n",
        "# the data, split between train and test sets\n",
        "(X_train, y_train), (X_test, y_test) = mnist.load_data()\n",
        "X_train = x_train.reshape(60000, 784)\n",
        "X_test = x_test.reshape(10000, 784)\n",
        "\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "\n",
        "mlp = MLPClassifier(hidden_layer_sizes=(8,8,8), activation='relu', solver='adam', max_iter=500)\n",
        "mlp.fit(X_train,y_train)\n",
        "\n",
        "predict_train = mlp.predict(X_train)\n",
        "predict_test = mlp.predict(X_test)\n",
        "\n",
        "from sklearn.metrics import classification_report,confusion_matrix\n",
        "print(confusion_matrix(y_train,predict_train))\n",
        "print(classification_report(y_train,predict_train))\n",
        "\n",
        "print(confusion_matrix(y_test,predict_test))\n",
        "print(classification_report(y_test,predict_test))"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[5484    2   20   53   15  267   56    2   22    2]\n",
            " [   0 6377  109    9   13   12   24   38  135   25]\n",
            " [  24   97 5139  236   70   51  187   61   88    5]\n",
            " [  19   34  269 5073    6  285   19   89  281   56]\n",
            " [  12   20   17    4 5361   50  140   33   14  191]\n",
            " [  48    8   45  241   81 4505   99    1  331   62]\n",
            " [  53   14   64    0   43  139 5567    1   36    1]\n",
            " [  26   51   46   30  134    5    0 5760    7  206]\n",
            " [   3  223   41  208   48  243   52   11 4881  141]\n",
            " [  32   11    3   93  386   62   10  134   64 5154]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.96      0.93      0.94      5923\n",
            "           1       0.93      0.95      0.94      6742\n",
            "           2       0.89      0.86      0.88      5958\n",
            "           3       0.85      0.83      0.84      6131\n",
            "           4       0.87      0.92      0.89      5842\n",
            "           5       0.80      0.83      0.82      5421\n",
            "           6       0.90      0.94      0.92      5918\n",
            "           7       0.94      0.92      0.93      6265\n",
            "           8       0.83      0.83      0.83      5851\n",
            "           9       0.88      0.87      0.87      5949\n",
            "\n",
            "    accuracy                           0.89     60000\n",
            "   macro avg       0.89      0.89      0.89     60000\n",
            "weighted avg       0.89      0.89      0.89     60000\n",
            "\n",
            "[[ 926    0    1    8    2   27   14    2    0    0]\n",
            " [   0 1098   13    1    1    1    4    1   14    2]\n",
            " [   8   10  875   48    9    3   32   18   26    3]\n",
            " [   6    5   39  836    3   46    2   14   51    8]\n",
            " [   2    4    2    0  899    6   21   11    1   36]\n",
            " [  16    1    8   62   19  704   14    1   52   15]\n",
            " [  24    1    5    0    7   29  884    1    7    0]\n",
            " [   2   15   15    8   14    1    0  923    1   49]\n",
            " [   2   33    6   36   20   61   10    7  777   22]\n",
            " [   5    1    1   15   84   13    1   27   13  849]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.93      0.94      0.94       980\n",
            "           1       0.94      0.97      0.95      1135\n",
            "           2       0.91      0.85      0.88      1032\n",
            "           3       0.82      0.83      0.83      1010\n",
            "           4       0.85      0.92      0.88       982\n",
            "           5       0.79      0.79      0.79       892\n",
            "           6       0.90      0.92      0.91       958\n",
            "           7       0.92      0.90      0.91      1028\n",
            "           8       0.82      0.80      0.81       974\n",
            "           9       0.86      0.84      0.85      1009\n",
            "\n",
            "    accuracy                           0.88     10000\n",
            "   macro avg       0.88      0.88      0.87     10000\n",
            "weighted avg       0.88      0.88      0.88     10000\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}