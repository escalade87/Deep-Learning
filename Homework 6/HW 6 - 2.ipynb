{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled9.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "iI7gBR7swzQx",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 799
        },
        "outputId": "6db2a25f-e369-4957-f54e-6ecd2d48d9f0"
      },
      "source": [
        "# USAGE\n",
        "# python train_unsupervised_autoencoder.py --dataset output/images.pickle --model output/autoencoder.model\n",
        "\n",
        "# set the matplotlib backend so figures can be saved in the background\n",
        "import matplotlib\n",
        "matplotlib.use(\"Agg\")\n",
        "\n",
        "# import the necessary packages\n",
        "from pyimagesearch.convautoencoder import ConvAutoencoder\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.datasets import mnist\n",
        "from sklearn.model_selection import train_test_split\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import argparse\n",
        "import random\n",
        "import pickle\n",
        "import cv2\n",
        "\n",
        "def build_unsupervised_dataset(data, labels, validLabel=1,\n",
        "\tanomalyLabel=3, contam=0.01, seed=42):\n",
        "\t# grab all indexes of the supplied class label that are *truly*\n",
        "\t# that particular label, then grab the indexes of the image\n",
        "\t# labels that will serve as our \"anomalies\"\n",
        "\tvalidIdxs = np.where(labels == validLabel)[0]\n",
        "\tanomalyIdxs = np.where(labels == anomalyLabel)[0]\n",
        "\n",
        "\t# randomly shuffle both sets of indexes\n",
        "\trandom.shuffle(validIdxs)\n",
        "\trandom.shuffle(anomalyIdxs)\n",
        "\n",
        "\t# compute the total number of anomaly data points to select\n",
        "\ti = int(len(validIdxs) * contam)\n",
        "\tanomalyIdxs = anomalyIdxs[:i]\n",
        "\n",
        "\t# use NumPy array indexing to extract both the valid images and\n",
        "\t# \"anomlay\" images\n",
        "\tvalidImages = data[validIdxs]\n",
        "\tanomalyImages = data[anomalyIdxs]\n",
        "\n",
        "\t# stack the valid images and anomaly images together to form a\n",
        "\t# single data matrix and then shuffle the rows\n",
        "\timages = np.vstack([validImages, anomalyImages])\n",
        "\tnp.random.seed(seed)\n",
        "\tnp.random.shuffle(images)\n",
        "\n",
        "\t# return the set of images\n",
        "\treturn images\n",
        "\n",
        "def visualize_predictions(decoded, gt, samples=10):\n",
        "\t# initialize our list of output images\n",
        "\toutputs = None\n",
        "\n",
        "\t# loop over our number of output samples\n",
        "\tfor i in range(0, samples):\n",
        "\t\t# grab the original image and reconstructed image\n",
        "\t\toriginal = (gt[i] * 255).astype(\"uint8\")\n",
        "\t\trecon = (decoded[i] * 255).astype(\"uint8\")\n",
        "\n",
        "\t\t# stack the original and reconstructed image side-by-side\n",
        "\t\toutput = np.hstack([original, recon])\n",
        "\n",
        "\t\t# if the outputs array is empty, initialize it as the current\n",
        "\t\t# side-by-side image display\n",
        "\t\tif outputs is None:\n",
        "\t\t\toutputs = output\n",
        "\n",
        "\t\t# otherwise, vertically stack the outputs\n",
        "\t\telse:\n",
        "\t\t\toutputs = np.vstack([outputs, output])\n",
        "\n",
        "\t# return the output images\n",
        "\treturn outputs\n",
        "\n",
        "# construct the argument parse and parse the arguments\n",
        "# ap = argparse.ArgumentParser()\n",
        "# ap.add_argument(\"-d\", \"--dataset\", type=str, default=\"output/images.pickle\", \n",
        "# \thelp=\"path to output dataset file\")\n",
        "# ap.add_argument(\"-m\", \"--model\", type=str, default=\"output/autoencoder.model\", \n",
        "# \thelp=\"path to output trained autoencoder\")\n",
        "# ap.add_argument(\"-v\", \"--vis\", type=str, default=\"recon_vis.png\",\n",
        "# \thelp=\"path to output reconstruction visualization file\")\n",
        "# ap.add_argument(\"-p\", \"--plot\", type=str, default=\"plot.png\",\n",
        "# \thelp=\"path to output plot file\")\n",
        "# args = vars(ap.parse_args())\n",
        "args = {}\n",
        "args[\"vis\"]=\"recon_vis.png\"\n",
        "args[\"model\"]=\"output/autoencoder.model\"\n",
        "args[\"dataset\"]=\"output/images.pickle\"\n",
        "args[\"plot\"]=\"plot.png\"\n",
        "\n",
        "# initialize the number of epochs to train for, initial learning rate,\n",
        "# and batch size\n",
        "EPOCHS = 20\n",
        "INIT_LR = 1e-3\n",
        "BS = 32\n",
        "\n",
        "# load the MNIST dataset\n",
        "print(\"[INFO] loading MNIST dataset...\")\n",
        "((trainX, trainY), (testX, testY)) = mnist.load_data()\n",
        "\n",
        "# build our unsupervised dataset of images with a small amount of\n",
        "# contamination (i.e., anomalies) added into it\n",
        "print(\"[INFO] creating unsupervised dataset...\")\n",
        "images = build_unsupervised_dataset(trainX, trainY, validLabel=0,\n",
        "\tanomalyLabel=3, contam=0.01)\n",
        "\n",
        "# add a channel dimension to every image in the dataset, then scale\n",
        "# the pixel intensities to the range [0, 1]\n",
        "images = np.expand_dims(images, axis=-1)\n",
        "images = images.astype(\"float32\") / 255.0\n",
        "\n",
        "# construct the training and testing split\n",
        "(trainX, testX) = train_test_split(images, test_size=0.2,\n",
        "\trandom_state=42)\n",
        "\n",
        "# construct our convolutional autoencoder\n",
        "print(\"[INFO] building autoencoder...\")\n",
        "(encoder, decoder, autoencoder) = ConvAutoencoder.build(28, 28, 1)\n",
        "opt = Adam(lr=INIT_LR, decay=INIT_LR / EPOCHS)\n",
        "autoencoder.compile(loss=\"mse\", optimizer=opt)\n",
        "\n",
        "# train the convolutional autoencoder\n",
        "H = autoencoder.fit(\n",
        "\ttrainX, trainX,\n",
        "\tvalidation_data=(testX, testX),\n",
        "\tepochs=EPOCHS,\n",
        "\tbatch_size=BS)\n",
        "\n",
        "# use the convolutional autoencoder to make predictions on the\n",
        "# testing images, construct the visualization, and then save it\n",
        "# to disk\n",
        "print(\"[INFO] making predictions...\")\n",
        "decoded = autoencoder.predict(testX)\n",
        "vis = visualize_predictions(decoded, testX)\n",
        "cv2.imwrite(args[\"vis\"], vis)\n",
        "\n",
        "# construct a plot that plots and saves the training history\n",
        "N = np.arange(0, EPOCHS)\n",
        "plt.style.use(\"ggplot\")\n",
        "plt.figure()\n",
        "plt.plot(N, H.history[\"loss\"], label=\"train_loss\")\n",
        "plt.plot(N, H.history[\"val_loss\"], label=\"val_loss\")\n",
        "plt.title(\"Training Loss\")\n",
        "plt.xlabel(\"Epoch #\")\n",
        "plt.ylabel(\"Loss\")\n",
        "plt.legend(loc=\"lower left\")\n",
        "plt.savefig(args[\"plot\"])\n",
        "\n",
        "# serialize the image data to disk\n",
        "print(\"[INFO] saving image data...\")\n",
        "f = open(args[\"dataset\"], \"wb\")\n",
        "f.write(pickle.dumps(images))\n",
        "f.close()\n",
        "\n",
        "# serialize the autoencoder model to disk\n",
        "print(\"[INFO] saving autoencoder...\")\n",
        "autoencoder.save(args[\"model\"], save_format=\"h5\")"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[INFO] loading MNIST dataset...\n",
            "[INFO] creating unsupervised dataset...\n",
            "[INFO] building autoencoder...\n",
            "Epoch 1/20\n",
            "150/150 [==============================] - 11s 76ms/step - loss: 0.0508 - val_loss: 0.0952\n",
            "Epoch 2/20\n",
            "150/150 [==============================] - 11s 76ms/step - loss: 0.0148 - val_loss: 0.0459\n",
            "Epoch 3/20\n",
            "150/150 [==============================] - 11s 75ms/step - loss: 0.0110 - val_loss: 0.0180\n",
            "Epoch 4/20\n",
            "150/150 [==============================] - 11s 75ms/step - loss: 0.0099 - val_loss: 0.0097\n",
            "Epoch 5/20\n",
            "150/150 [==============================] - 11s 75ms/step - loss: 0.0093 - val_loss: 0.0089\n",
            "Epoch 6/20\n",
            "150/150 [==============================] - 11s 75ms/step - loss: 0.0091 - val_loss: 0.0089\n",
            "Epoch 7/20\n",
            "150/150 [==============================] - 11s 75ms/step - loss: 0.0085 - val_loss: 0.0087\n",
            "Epoch 8/20\n",
            "150/150 [==============================] - 11s 76ms/step - loss: 0.0084 - val_loss: 0.0085\n",
            "Epoch 9/20\n",
            "150/150 [==============================] - 11s 75ms/step - loss: 0.0080 - val_loss: 0.0082\n",
            "Epoch 10/20\n",
            "150/150 [==============================] - 11s 76ms/step - loss: 0.0080 - val_loss: 0.0082\n",
            "Epoch 11/20\n",
            "150/150 [==============================] - 11s 76ms/step - loss: 0.0076 - val_loss: 0.0081\n",
            "Epoch 12/20\n",
            "150/150 [==============================] - 11s 75ms/step - loss: 0.0076 - val_loss: 0.0083\n",
            "Epoch 13/20\n",
            "150/150 [==============================] - 11s 76ms/step - loss: 0.0074 - val_loss: 0.0079\n",
            "Epoch 14/20\n",
            "150/150 [==============================] - 11s 76ms/step - loss: 0.0072 - val_loss: 0.0083\n",
            "Epoch 15/20\n",
            "150/150 [==============================] - 11s 75ms/step - loss: 0.0072 - val_loss: 0.0079\n",
            "Epoch 16/20\n",
            "150/150 [==============================] - 11s 76ms/step - loss: 0.0071 - val_loss: 0.0080\n",
            "Epoch 17/20\n",
            "150/150 [==============================] - 11s 76ms/step - loss: 0.0069 - val_loss: 0.0076\n",
            "Epoch 18/20\n",
            "150/150 [==============================] - 11s 77ms/step - loss: 0.0068 - val_loss: 0.0080\n",
            "Epoch 19/20\n",
            "150/150 [==============================] - 11s 77ms/step - loss: 0.0067 - val_loss: 0.0076\n",
            "Epoch 20/20\n",
            "150/150 [==============================] - 11s 76ms/step - loss: 0.0066 - val_loss: 0.0076\n",
            "[INFO] making predictions...\n",
            "[INFO] saving image data...\n",
            "[INFO] saving autoencoder...\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}